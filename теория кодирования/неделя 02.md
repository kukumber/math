# задача исправления ошибок

Типы ошибок:
- ошибки замещения: муха $\rightarrow$ мука
	- симметричные
	- несимметричные
- ошибки стирания: муха $\rightarrow$ му?а
- ошибки выпадения: муха $\rightarrow$ уха
- ошибки вставки: мука $\rightarrow$ мурка
- комбинации перечисленных типов

Всегда задаются ограничения на «надежность» канала, например:
- верхняя оценка числа ошибок на одно сообщение (детерминированные ограничения)
- вероятность возникновения ошибки на один символ сообщения (вероятностные ограничения)

## коды

Пусть $\mathbb{A}_q$ — алфавит канала, $|\mathbb{A}_q|= q$.

$q$-*ичным* кодом называется любое подмножество
$$C\subseteq \mathbb{A}^n_q$$
$n$ — *длина кода* (длина кодовых слов)
$|C|$ — *мощность кода* (число кодовых слов)

Чаще всего рассматривают *двоичные коды*, то есть когда $q=2$ и $\mathbb{A}_q = \{0,1\}$.

Для произвольного двоичного слова $\mathbf{a}$ будем через $\|\mathbf{a}\|$ обозначать *вес слова* (количество ненулевых компонент), то есть величину
$$\#\{i|a_i\ne 0\}$$

## обнаружение/исправление ошибок

Пусть $\mathbf{a}$ и $\mathbf{b}$ — слова в алфавите канала, то есть в том алфавите, в котором они должны быть записаны, чтобы быть переданными по каналу связи.

Обозначим $\tilde{d}(\mathbf{a},\mathbf{b})$ — минимальное количество ошибок, в результате которых $\mathbf{a}$ может перейти в $\mathbf{b}$. Этот параметр характеризует то, насколько "плохо может канал поступить со словом".

Способ кодирования позволяет *обнаруживать $k$ ошибок*, если для любых различных кодовых сообщений $\mathbf{a}'$ и $\mathbf{a}''$ при передаче в канал (в котором происходит $\le k$ ошибок) слова $\mathbf{a}'$ на выходе не может получиться $\mathbf{a}''$.

Формально:
$$\nexists \mathbf{a}',\mathbf{a}''\in C: \mathbf{a}'\ne\mathbf{a}'' \wedge \ \tilde{d}(\mathbf{a}',\mathbf{a}'')\le k$$

Способ кодирования позволяет *исправлять $k$ ошибок*, если при передаче в канал различных кодовых сообщений $\mathbf{a}'$ и $\mathbf{a}''$ на выходе из канала будут получаться различные сообщения (при условии, что с каждым отдельным сообщением в канале происходит не более $k$ ошибок).

Формально:
$$\nexists\mathbf{a}',\mathbf{a}''\in C, \mathbf{a}: \big(\mathbf{a}'\ne\mathbf{a}'' \wedge \ \tilde{d}(\mathbf{a}',\mathbf{a})\le k \ \wedge \ \tilde{d}(\mathbf{a}'',\mathbf{a})\le k\big)$$

## метрики Хемминга и Левенштейна

Особенно удобно, когда $\tilde{d}$ является *метрикой*:
- она симметрична:
$$\forall \mathbf{a},\mathbf{b} \ \tilde{d}(\mathbf{a},\mathbf{b})=\tilde{d}(\mathbf{b},\mathbf{a})$$
- для двух различных слов метрика должна быть больше нуля:
$$\forall \mathbf{a} \ne \mathbf{b} \ \tilde{d}(\mathbf{a},\mathbf{b})>0$$
- для двух совпадающих слов метрика должна быть равна нулю:
$$\forall \mathbf{a} \ \tilde{d}(\mathbf{a}, \mathbf{a})=0$$
- должно соблюдаться неравенство треугольника:
$$\forall \mathbf{a}, \mathbf{b}, \mathbf{c} \ \tilde{d}(\mathbf{a}, \mathbf{b})\le \tilde{d}(\mathbf{a}, \mathbf{c}) + \tilde{d}(\mathbf{c},\mathbf{b})$$

Так бывает не всегда. Например, если в канале есть только ошибки вставки и никаких других, то при $\mathbf{a}\ne \mathbf{b}$ по крайней мере одна из двух величин $\tilde{d}(\mathbf{a},\mathbf{b}),\tilde{d}(\mathbf{b},\mathbf{a})$ вовсе не определена.

### метрика Хемминга

Если рассматриваются слова одной и той же длины, а в канале возможны **только ошибки типа замещения** (любые), то 
$$\tilde{d}(\mathbf{a}, \mathbf{b})=d_X(\mathbf{a},\mathbf{b})$$
где
$$d_X(\mathbf{a}, \mathbf{b}):=\#\{i |a_i\ne b_i\}$$
Расстояние между словами $\mathbf{a}$ и $\mathbf{b}$ равняется количеству позиций, в которых слова $\mathbf{a}$ и $\mathbf{b}$ различаются.

Функционал $d_X$ — *метрика Хемминга*, $d_X(\mathbf{a},\mathbf{b})$ — *расстояние Хемминга* между $\mathbf{a}$ и $\mathbf{b}$.

Например $d_X(010, 100)=2$, потому что эти слова различаются в первой и второй координате.

### метрика Левенштейна

Если в канале происходят **ошибки выпадения/вставки**, то канал описывается *метрикой Левенштейна*:
$$d_L(\mathbf{a},\mathbf{b})=\min\#\text{ выпадений и вставок, переводящих }\mathbf{a} \text{ в } \mathbf{b}$$
Например:
- $d_L(010, 00)=1$
- $d_L(011010,01001)=3$

## кодовое расстояние

Пусть $\tilde{d}(\cdot,\cdot)$ — метрика, $C$ — код.

*Кодовым расстоянием* кода $C$ называется величина
$$\tilde{d}(C):=\min_{\mathbf{a}\ne\mathbf{b}; \ \mathbf{a},\mathbf{b}\in C}\tilde{d}(\mathbf{a},\mathbf{b})$$
минимальное расстояние между всеми возможными парами кодовых слов.

Кодовым расстоянием полностью определяется способность кода противостоять ошибкам. Для того, чтобы код обнаруживал $t$ ошибок, необходимо и достаточно:

- $C$ обнаруживает $t$ ошибок $\Leftrightarrow \tilde{d}(C)>t$
- $C$ исправляет $t$ ошибок $\Leftrightarrow\tilde{d}(C)>2t$

Если кодовое расстояние больше $t$, то для любых двух кодовых слов одно из другого получается только, если произойдет строго больше $t$ ошибок. Если происходит $t$ ошибок, то одно слово в другое не переходит. В этом случае, если в канал передавалось кодовое слово, то на выходе получается либо оно само, либо какое-то слово, не совпадающее ни с одним из кодовых.

Если $\Leftrightarrow\tilde{d}(C)>2t$, то это означает, что для любых двух различных кодовых слов расстояние между ними больше, чем $2t$. Представим, что код не может исправлять ошибки, это означает, что нашлись какие-то два слова $a'$ и $a''$, которые при передаче в канал на выходе дали одно и то же слово $a$. Это означает, что $\tilde{d}(a',a)\le t$ и $\tilde{d}(a'',a)\le t$, также по симметричности метрики это означает, что $\tilde{d}(a,a'')\le t$, и по неравенству треугольника получается, что расстояние $\tilde{d}(a',a'')\le 2t$.

Если бы нашлось два кодовых слова $a'$ и $a''$, которые получаются одно из другого при возникновении не более, чем $2t$ ошибок, то это означает, что существует цепочка слов, которая соединяет $a'$ и $a''$, где каждое следующее слово получается из предыдущего за счет внесения одной дополнительной ошибки. Значит в середине этой цепочки существует какое-то слово $a$, которое на расстоянии не больше, чем $t$ от $a'$ и не больше, чем $t$ от $a''$
![[неделя 02.png]]
В этом случае непонятно, с каким из слов соотнести полученное слово $a$.

## геометрическая интерпретация

*Шар радиуса* $r$ с центром в $\mathbf{a}$ — это множество таких слов, что расстояние от этих слов до слова $\mathbf{a}$ не превосходит $r$:
$$S_r(\mathbf{a}):=\{\mathbf{b}|\tilde{d}(\mathbf{a},\mathbf{b})\le r\}$$
Если в канал передавалось $\mathbf{a}$, то на выходе из канала может быть любое слово $\mathbf{b}\in S_t(\mathbf{a})$. Геометрически это означает, что в шар с радиусом $t$ с центром в точке $\mathbf{a}$ не попадает никакое другое кодовое слово $\mathbf{b}$.

Значит, код обнаруживает $t$ ошибок тогда и только тогда, когда никакое кодовое слово не попадает в шар радиуса $t$ с центром в другом кодовом слове:
![[неделя 02-1.png|w60]]

Код исправляет $t$ ошибок тогда и только тогда, когда при передаче в канал различных кодовых слов на выходе получаются различные слова, то есть когда шары радиуса $t$ с центрами в кодовых словах не пересекаются:
![[неделя 02-2.png|w80]]
## основные задачи теории кодов, исправляющих ошибки

**Основная задача**: строить коды, для которых:
- число кодовых слов как можно больше
- кодовое расстояние как можно больше
- длина кодовых слов как можно меньше

Геометрически эта **задача об упаковке**:
- возможно большего числа шаров
- возможно большего радиуса
- в пространстве возможно меньшей размерности

**Задачи, связанные с ресурсами**:
- процессы кодирования и декодирования (исправление ошибок) должны быть возможно менее трудоемкими по количеству операций и памяти

## коды Варшамова—Тененгольца

Код Варшамова—Тененгольца длины $n$:
$$C:=\bigg\{a_1a_2\ldots a_n| \sum_{i=1}^n ia_i\equiv 0\big(\text{mod }(n+1)\big)\bigg\}$$
Это множество слов длины $n$ таких, что сумма номеров позиций, умноженных на позицию равна нулю по модулю $n+1$. Рассматривать такую сумму — это все равно, что рассмотреть сумму номеров координат слова, равных единице.

Например, пусть $n=5$, рассмотрим слово 10001. Первая и пятая координаты равны единице, складываем координаты, получается 6. По модулю $n+1$ будет равно нулю. Значит это слово является словом в коде Варшамова—Тененгольца. Другой вариант 01011: сумма координат равна 11, оно не делится нацело на 6, значит это не слово в коде Варшамова—Тененгольца.

Для мощности кода справедлива формула:
$$|C|=\frac{1}{2(n+1)}\sum_{\substack{d|n+1 \\ d \text{ нечетно}}}\varphi(d)2^{(n+1)/d}$$
где $d$ — это нечетные делители числа $n+1$, $\varphi(d)$ — функция Эйлера (количество чисел меньше данного и взаимно простых с данным).

Асимптотически это максимально возможная мощность кода, исправляющего одну ошибку выпадения/вставки символа.

Пусть $C$ — код Варшамова—Тененгольца длины $n$, и пусть $\mathbf{a}\in C$.

Пусть в канал передали $\mathbf{a} = a_1\ldots a_n$, и на выходе получили слово длиной на единицу меньше
$$\mathbf{a}'=a_1'\ldots a_{n-1}'=a_1\ldots a_{k-1}a_{k+1}\ldots a_n$$
Задача по $\mathbf{a}'$ восстановить $\mathbf{a}$.

Восстановить $\mathbf{a}$ — не то же самое, что восстановить пару $(k, a_k)$.

Положим
$$\begin{aligned}
n_0 := \#\{i>k|a_i=0\} \\
n_1 := \#\{i>k|a_i=1\}
\end{aligned}$$
то есть, количество координат, правее $k$-ой и равных нулю и единице.

Если $a_k=0$, то $\mathbf{a}$ можно восстановить по $\mathbf{a}'$, если известно $n_1$.
Если $a_k=1$, то $\mathbf{a}$ можно восстановить по $\mathbf{a}'$, если известно $n_0$.

Например, если по какой-то причине известно, что выпал ноль, то идем справа и считаем единицы и, как только найдена по счету $n_1$ единица, сразу за ней ставим 0 и получаем исходное слово. Аналогично с выпавшей единицей.

### суммы S и S'

Рассмотрим для принятого слова сумму, аналогичную сумме в определении кодов Варшамова—Тененгольца. Для исходного слова
$$S:=\sum_{i=1}^n i a_i$$
то есть сумма номеров координат, помноженных на значение этой координаты 0 или 1 должна была равняться нулю по модулю $n+1$.

Так как принятое из канала слова имеет на единицу меньшую длину, для этого слова можно также посчитать сумму:
$$S' := \sum_{i=1}^{n-1} i a_i'$$
Посмотрим, насколько эти суммы различаются. Исходное слово выглядело как
$$a_1\ldots a_{k-1}\mathbf{a_k}a_{k+1}\ldots a_n$$
Начало слов до $a_k$ у отправленного и принятого сообщения совпадают, поэтому сумма координат от $a_1$ до $a_{k-1}$ будет одинаковой. Поэтому, чтобы найти разность $S$ и $S'$, необходимо вычесть эту повторяющуюся часть. Оставшаяся часть уже различается, так как произошел сдвиг на единицу назад, то есть, если умножение на пятой позиции происходило на 5, то теперь позиция становится четвертой и умножение производится на 4. Соответственно это можно записать как $ia_{i+1}$, чтобы компенсировать этот сдвиг:
$$S-S' = \sum_{i=1}^n ia_i-\bigg(\sum_{i=1}^{k-1}ia_i+\sum_{i=k}^{n-1}ia_{i+1}\bigg)=$$
от первых двух сумм остается произведение от $k$ до $n$, во второй сумме поменяем индекс суммирования, в этом случае умножение под знаком суммы будет происходить на $(i-1)$:
$$=\sum_{i=k}^n ia_i-\sum_{i=k+1}^n(i-1)a_i=$$
получившиеся две суммы имеют почти одинаковые слагаемые, отличие в том, что в первой сумме есть слагаемое $ka_k$, вынесем его отдельно. Все остальные слагаемые в суммах можно разбить по парам. Когда из слагаемого $ia_i$ вычитается слагаемое $(i-1)a_i$ остается просто само $a_i$:
$$= ka_k+\sum_{i=k+1}^na_i$$
Получается, что разность равна $ka_k$ плюс сумма координат, стоящих правее выпавшей, или количество единиц, стоящих правее выпавшего символа.

Получаем
$$S'=S-\bigg(ka_k+\sum_{i=k+1}^na_i\bigg)=S-ka_k-n_1$$
как говорилось выше, $n_1$ — это количество единиц, стоящих правее выпавшего символа.

Так как $S\equiv 0 \big(\text{mod}(n+1)\big)$, то
$$S'\equiv -n_1-ka_k\big(\text{mod}(n+1)\big)$$
Отсюда можно заключить, что если выпал 0, то есть $a_k=0$, то  $ka_k=0$ и 
$$(-S')\text{ mod }(n+1)= n_1$$
Если выпала 1, то есть $a_k=1$, то
$$(-S')\text{ mod }(n+1)= n_1+k=(n-k-n_0)+k=n-n_0$$
### исправление одной ошибки выпадения

Заметим, что правее символа $a_k$ в исходном слове стояло $n_1$ единиц и все они сохранились, и они дают вклад в вес слова $\mathbf{a}'$
$$\|\mathbf{a}'\|\ge n_1$$
С другой стороны, все нули, которые были в исходном слове и стояли правее выпавшей позиции тоже сохранились
$$\|\mathbf{a}'\|\le(n-1)-n_0$$
отсюда
$$n_1\le \|\mathbf{a}'\|< (n-n_0)$$

Итоговый алгоритм восстановления $\mathbf{a}$ по $\mathbf{a}'$:
- вычисляем величину
$$T:=\bigg(-\sum_{i=1}^{n-1}i a'_i\bigg)\text{ mod }(n+1)$$
- если $T\le \|\mathbf{a}'\|$, то в $\mathbf{a}'$ вставляем 0 перед $T$-й с конца единицей
- если $T>\|\mathbf{a}'\|$, то в $\mathbf{a}'$ вставляем 1 перед $(n-T)$-м с конца нулем

### исправление одной ошибки вставки

Исправление ошибки вставки более сложная задача, потому что больше степеней свободы. При удалении канал может только удалить в одном положении, при вставке: канал вставляет на какую-то позицию и вставляет определенный символ.

Рассмотрим задачу, когда $\mathbf{a}'$ получено из $\mathbf{a}$ вставкой символа:
$$\mathbf{a}'=\ldots a_k xa_k+1\ldots$$
Если $k=0$, то $\mathbf{a}'=x\mathbf{a}$; если $k=n$, то $\mathbf{a}'=ax$

До $k$-й позиции включительно полностью совпадают слагаемые суммы $S$ и $S'$. Есть $x$, который умножается на $(k+1$). Затем все символы, которые стоят после $k$-й позиции:
$$S'=S+(k+1)x+\sum_{i>k}a_i\equiv$$
$S \text{ mod }(n+1)=0$, поэтому остается только два слагаемых
$$\equiv(k+1)x+\sum_{i>k}a_i=$$
сумма всех $a_i$, где $i>k$ равна $n_1$
$$=(k+1)x+n_1$$
Положим $T:=S' \text{ mod }(n+1)$

#### Случай,  когда $T=0$

Так как $S'\equiv(k+1)x+n_1$.  Это означает, что эта сумма либо равна нулю, либо $(n+1)$.

Если $(k+1)x+n_1=0$, тогда $x=0$ и $a_{k+1}=\ldots= a_n = 0$, то есть, правее вставленной позиции нет ни одной единицы.

Если $(k+1)x+n_1=(n+1)$, тогда $x=1$ и $a_{k+1} = \ldots = a_n = 1$, то есть правее вставленной позиции одни единицы.

В обоих случаях $\mathbf{a}$ получается из $\mathbf{a}'$ удалением последнего символа.

#### Случай, когда $T=\|\mathbf{a}'\| > 0$

То есть, $T$ совпадает с весом слова.

Это может быть только если $x=0$
$$a_1=\ldots=a_k=x=0$$
В этом случае $T= n_1$. То есть, единицы, стоящие правее вставленной позиции, это все единицы, которые есть в принятом слове. Левее вставленной позиции все нули. 

Второй случай, когда $x=1$
$$a_1=\ldots=a_k=x=1$$
Тогда $T=n_1+k+1$. Это возможно только тогда, когда все символы левее вставленного, включая вставленный, равны единице.

В обоих этих случаях требуется удалить первый символ.

#### Случай, когда $0< T\ne\|\mathbf{a}'\|$

Если $x=0$,  тогда $T=n_1< \|\mathbf{a}'\|$.  В этом случае мы знаем, что правее нуля $n_1$ единиц, то отсчитываем справа $n_1$ единиц и удаляем следующий ноль.

Если $x=1$, тогда $T=k+1+n_1 > \|\mathbf{a}'\|$. При этом оказывается, что
$$T=k+1+(n-k-n_0)=n+1-n_0$$
где $(n-k)$ — это отрезок правее вставленного символа. В этом случае отсчитываем $n_0$ нулей справа и следующую единицу удаляем.

### возможные обобщения кодов Варшамова—Тененгольца

- произвольный фиксированный модуль $l>n$
$$\{a_1a_2\ldots a_n|\sum_{i=1}^n ia_i\equiv 0 (\text{mod l})\}$$

- дополнительные соотношения, например
$$\{a_1a_2\ldots a_n|\sum_{i=1}^n ia_i\equiv \sum_{i=1}^n i^2a_i\equiv(\text{mod l})\}$$

## обозначение

$(n, M, d)_q$ — это обозначение, в котором:
- $n$ — длина кодовых слов
- $M$ — количество слов в коде
- $d$ — кодовое расстояние (метрика Хемминга)
- $q$ — мощность алфавита, в котором записаны кодовые слова
 
Если $q=2$, то часто вместо $(\ldots, \ldots,\ldots)_2$ пишут просто $(\ldots, \ldots,\ldots)$.

## граница Хемминга

Граница — это специальный тип теорем в теории кодирования, которые дают границы возможностей.

### граница сферической упаковки

Для любого $(n, M, d)_q$-кода имеем
$$M\le\frac{q^n}{|S_{\lfloor(d-1)/2\rfloor}(\mathbf{0})|}$$
в двоичном случае
$$M\le\frac{2^n}{\sum_{k=0}^{\lfloor(d-1)/2\rfloor}\binom{n}{k}}$$
Коды, достигающие эту границу, называют *совершенными* или *плотно упакованными*.

Для двоичного случая $\sum_{k=0}^{\lfloor(d-1)/2\rfloor}\binom{n}{k}$ получается следующим образом. Центр шара — это слово из одних нулей. Есть все слова, находящиеся на расстоянии 1 от центра, для слова из одних нулей таких слов $n$ штук. На расстоянии 2 — $C_n^2$ и так далее. Размер шара получается $\binom{n}{k}$. Последний слой — это слова, удаленные на расстояние $\lfloor(d-1)/2\rfloor$ от центра, то в этих пределах и суммируем.

**доказательство**

Пусть $C=\{a_1, a_2,\ldots,a_M\}$ — $(n,M,d)_q$ код
![[неделя 02-3.png|w75]]
Между двумя кодовыми словами расстояние как минимум $d$. Если взять шары радиусом $\lfloor d-1/2\rfloor$, то такие шары точно не пересекаются.

Получается, что в пространство ограниченного объема размещены шары, объем каждого из которых равен мощности множества
$$|S_{\lfloor(d-1)/2\rfloor}(\mathbf{0})|$$
0 здесь можно написать по причине того, что объем шара не зависит от того, где у этого шара центр. 

Раз шары не пересекаются, значит сумма их объемов не превосходит объем всего ящика. Отсюда
$$q^n\ge\sum_{i=1}^M|S_{\lfloor(d-1)/2\rfloor}(\mathbf{a_j})|=M\cdot|S_{\lfloor(d-1)/2\rfloor}(\mathbf{0})|$$

## обратная теорема к границе Хемминга

Пусть числа $q,n,M,d\in \mathbb{N}$ таковы, что
$$M\le\frac{q^n}{|S_d(\mathbf{0})|}$$
тогда существует $(n,M,d)_q$-код.

**доказательство**

Пусть $|C|=\{a_1, \ldots, a_{|C|}\}$ — код максимальной мощности с кодовым расстоянием $d$ и длиной слов $n$
![[неделя 02-4.png|w50]]

Возьмем радиусы шаров равными $d$. Все точки пространства $\mathbb{A}_q^n$, все слова длины $n$ в $q$-ичном алфавите оказываются покрыты этими шарами. То есть, каждое слово длины $n$ попадает хотя бы в один из этих шаров.

Если бы нашлось какое-то слово, которое не попало ни в один из шаров с центрами в кодовых словах радиуса $d$, то это слово можно было бы добавить к коду. По-прежнему получалось бы, что никакое кодовое слово не попадает в шар с радиусом $d$ и центром в другом кодовом слове. Значит код по-прежнему с кодовым расстоянием $d$, но мощность на 1 больше, чем у исходного кода $C$. Это противоречило бы тому, что код $C$ взят как код максимальной мощности.

Раз получается покрытие, то есть, нет точек, которым удалось избежать все шары, то получается, что сумма объемов шаров с центрами в кодовых словах радиуса $d$ должна быть не меньше, чем объем пространства
$$\sum_{j=1}^{|C|}|S_d(\mathbf{a_j})|\ge q^n$$
Объем каждого шара не зависит от цента шара
$$|S_d(\mathbf{a_j})|=|S_d(\mathbf{0})|$$
Получается, что в сумме все слагаемые одинаков, тогда эта сумма равна
$$|C|\cdot|S_d(\mathbf{0})|=\sum_{j=1}^{|C|}|S_d(\mathbf{a_j})|\ge q^n$$
поделив обе части на объем шара, получаем, что мощность кода $|C|$ не меньше, чем $q^n$, поделенная на объем шара.

## граница Синглтона

Для любого $(n, M, d)_q$-кода имеем
$$M\le q^{n-d+1}$$
Коды, на которых достигается граница Синглтона, называются $MDS$-кодами (maximum distance separable codes).

**доказательство**

Возьмем код $C=\{a_1, \ldots, a_M\}$ с параметрами $(n, M, d)_q$.

Представим слова этого кода в виде вектора отдельных слов с M строками длины $n$. 

Удалим из этой таблицы первые $(d-1)$ столбцов. Утверждается, что в этой матрице все строки по-прежнему различны.

Допустим, совпало два слова. Тогда, даже если добавим $(d-1)$ позицию, и даже, если все буквы в этих позициях разные, все равно между этими двумя словами получается расстояние не больше, чем $(d-1)$. Кодовое расстояние $d$. Получается противоречие.

Так как в урезанной матрице длина слов равна $(n-d+1)$, количество слов в ней не больше, чем количество всех слов длины $(n-d+1)$. Количество таких слов $q^{n-d+1}$. Так как слова различных, значит их не больше, чем  $q^{n-d+1}$.

## граница Плоткина

Пусть $nr<d$, где $r:=1-\frac{1}{q}$. Тогда для любого $(n, M, d)_q$-кода
$$M\le \bigg\lfloor\frac{d}{d-nr}\bigg\rfloor$$
**доказательство**

Возьмем код $(n, M, d)_q$. Рассмотрим матрицу, в которой по строкам выписаны все кодовые слова
$$\begin{pmatrix}
\mathbf{a}_1\\
\vdots\\
\mathbf{a}_M
\end{pmatrix}$$
Элементы этой матрицы будем обозначать $a_{ij}$ — $j$-я по счету координата $i$-го по счету кодового слова.

Рассмотрим сумму
$$T:=\sum_{\substack{1\le k \le n\\1\le i<j\le M}}\mathbb{1}_{a_{ik}\ne a_{jk}}$$
То есть сумма индикаторов того, что $a_{ik}$ не совпадает с $a_{jk}$. То есть, проверяем все пары символов в каждом слове в одном и том же столбце.

Сумму можно расписать в виде двух сумм
$$T=\sum_{1\le i<j\le M}\sum_{1\le k \le n\\}\mathbb{1}_{a_{ik}\ne a_{jk}}=$$
правая сумма — это прохождение по двум зафиксированным словам и проверка символов в столбце на одинаковость. Эта сумма должна быть не меньше, чем кодовое расстояние между этими двумя словами, поэтому можно записать
$$=\sum_{1\le i<j\le M}d(\mathbf{a}_i, \mathbf{a}_j)$$
отсюда
$$T\ge\frac{M\cdot (M-1)}{2}\cdot d$$где $\frac{M\cdot (M-1)}{2}$ — это количество способов выбрать две строчки из $M$ строк матрицы, что можно записать как $\binom{M}{2}$, каждая такая строка оценивается снизу кодовым расстоянием $d$.

Если в $k$-м столбце $x_s$ кодовых слов имеют координату равную $s$, то тогда сумма индикаторов будет равна сумме всевозможных произведений по всем различным $s$:
$$\sum_{1\le k \le n\\}\mathbb{1}_{a_{ik}\ne a_{jk}}=\sum_{s'\ne s''}x_{s'}\cdot x_{s''}$$
Рассмотрим $k$-й столбец. Будем считать, что этот столбец переупорядочен так, что сначала в этом столбце идут нули, потом единицы и так далее, затем символы под номером $(q-1)$. Множество $\mathbb{A}_q=\{0,\ldots,q-1\}$. Количество нулей $x_0$, единиц $x_1$, координат $(q-1)$  — $x_{q-1}$. Соответственно пара возникает, когда взяты элементы из разных групп. 

Например, если берутся пары из групп $x_0$ и $x_1$, то их общее количество будет равно $x_0\cdot x_1$. 

Преобразуем сумму произведений. Из формулы сокращенного умножения следует:
$$\sum_{s'\ne s''}x_{s'}\cdot x_{s''}=\frac{1}{2}\bigg(\bigg(\sum_{s}x_s\bigg)^2-\sum_{s}x^2_s\bigg)=$$
Сумма всех $x$ — это высота столбца, которая у нас равна $M$:
$$=\frac{1}{2}\bigg(M^2-\sum_{s}x^2_s\bigg)$$
Максимум выражения $\sum_{s'\ne s''}x_{s'}\cdot x_{s''}$ достигается тогда, когда достигается минимум выражения $\sum_{s}x^2_s$. Минимум суммы квадратов величин достигается тогда, когда все эти величины равны одному и тому же. Если сумма всех $x=M$, их количество равно $q$, то все эти $x$, если они равны одному и тому же значению, равны $M/q$. Это следует из неравенства Коши-Буняковского.

Оценить сумму квадратов $x$ снизу можно величиной $q\cdot\frac{M^2}{q^2}$
$$\frac{1}{2}\bigg(M^2-\sum_{s}x^2_s\bigg)\le\frac{1}{2}\bigg(M^2-q\frac{M^2}{q^2}\bigg)=\frac{M^2}{2}\bigg(1-\frac{1}{q}\bigg)$$

При любом значении $k$ получаем оценку:
$$\sum_{s'\ne s''}x_{s'}\cdot x_{s''}\le\frac{M^2}{2}\bigg(1-\frac{1}{q}\bigg)$$
Значит для величины $T$ верхня оценка:
$$T=\sum_{1\le i<j\le M}\sum_{1\le k \le n\\}\mathbb{1}_{a_{ik}\ne a_{jk}}\le\frac{nM^2}{2}\bigg(1-\frac{1}{q}\bigg)$$
Сопоставим верхнюю и нижнюю оценки:
$$\frac{M\cdot (M-1)}{2}\cdot d \le T\le\frac{M^2}{2}\bigg(1-\frac{1}{q}\bigg)$$
Величина $\bigg(1-\frac{1}{q}\bigg)$ — это $r$, отсюда, при сокращении:
$$(M-1)\cdot d\le nrM$$
Далее можно получить неравенство
$$M(d-nr)\le d$$
Так как по условию $(d-nr)>0$ и $M\in\mathbb{Z}$, то можно переписать как
$$M\le\bigg\lfloor\frac{d}{d-rn}\bigg\rfloor$$
