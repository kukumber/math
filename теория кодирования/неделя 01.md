# алфавитное кодирование

Простейший подход:
- каждой букве языка, а также знакам препинания сопоставляем по двоичному слову
- тогда текст кодируется записью друг за другом кодов отдельных букв

Так сделано в таблицах ASCII, Unicode.

## математическая модель

Математически эту задачу можно сформулировать следующим образом. Даны алфавиты
$$\mathbb{A}=\{a_1,\ldots,a_n\},\mathbb{B}=\{b_1,\ldots,b_q\}$$
Алфавит $\mathbb{A}$ — **кодируемый**, «естественный»
Алфавит $\mathbb{B}$ — **кодовый** (например, $\mathbb{B}=\{0,1\}$)

Алфавитным кодированием называется отображение множества всех слов, записанных в естественном алфавите в множество слов, записанных в кодовом алфавите:
$$\varphi:\mathbb{A}^\ast\to\mathbb{B}^\ast$$
$^\ast$ означает, что то, что получается — это множество всевозможных слов, у которых каждый отдельный символ (каждая отдельная координата) принадлежит исходному множеству. То есть, множество $\mathbb{A}^\ast$ — это множество всех слов, у которых каждый символ взят из алфавита $\mathbb{A}$.

Отображение такое, что для любых $a_{i_1},\ldots,a_{i_r}$ выполнено:
$$\varphi(a_{i_1},\ldots,a_{i_r})=\varphi(a_{i_1})\ldots\varphi(a_{i_r})$$
Другими словами, когда кодируется слово, результат должен совпадать с кодированием букв по отдельности. То есть, достаточно определить $\varphi$ на отдельных символах алфавита $\mathbb{A}$:
$$\begin{aligned}
\varphi(a_1)&=B_1\\
\vdots\\
\varphi(a_n)&=B_n
\end{aligned}$$
Слова $B_1,\ldots,B_n$ называются **кодовыми**, совокупность $\{B_1,\ldots,B_n\}$ называется **кодом**.
Везде далее считаем, что все $B_i$ различны, иначе кодирование не однозначное

## однозначность кодирования

Кодирование $\varphi$ называется **однозначным**, если, закодировав два разных слова, записанных в естественном алфавите, будут получены два разных слова, записанных в кодовом алфавите
$$\varphi(w')\ne\varphi(w''), \text{ при } w'\ne w''$$
Однозначность не зависит от исходного алфавита $\mathbb{A}$, а целиком определяется набором  $\{B_1,\ldots,B_n\}$.

Кодирование однозначное тогда и только тогда, когда никакое слово $b_{i_1}b_{i_2}\ldots b_{i_r}$ нельзя двумя разными способами разбить на кодовые слова
![[теория кодирования/images/неделя 01.png|w50]]
В этом случае нельзя однозначно определить, какое из двух слов было закодировано $a_3a_8$ или $a_5a_1a_3$.
### достаточные условия однозначности

- **равномерность**
$$|B_1|=|B_2|=\ldots=|B_n|$$
длина всех кодовых слов одинакова

- **свойство префикса** (беспрефиксность кода)
$$\nexists i,j(i\ne j \text{ и }B_i=B_jw,\text{ где }w\in \mathbb{B}^\ast)$$
то есть, не существует двух кодовых слов таких, что одно из этих слов является префиксом другого слова

- **свойство суффикса**
$$\nexists i,j(i\ne j \text{ и }B_i=wB_j,\text{ где }w\in \mathbb{B}^\ast)$$
то есть, не существует двух кодовых слов таких, что одно из этих слов является суффиксом другого слова

Равномерность, префиксность и суффиксность не являются необходимыми условиями для однозначности. Пример:
$$\begin{aligned}
&\mathbb{A}=\{a_1,a_2\}\\
&\mathbb{B}=\{0,1\}\\
&\varphi(a_1)=0\\
&\varphi(a_2)=010
\end{aligned}$$

#### префиксные коды — «мгновенные»

Префиксные коды называются ещё **мгновенными**, так как закодированные с их помощью сообщения можно декодировать по мере приёма, без задержек
![[теория кодирования/images/неделя 01-1.png|w75]]
Если закодировать какое-то слово с помощью префиксного кода и передать по каналу связи, то адресат может начинать декодирование по мере приема данных, не дожидаясь окончания передачи.

### вывод критерия однозначности

Код неоднозначен, если найдется слово $B\in\mathbb{B}^\ast$, которое не менее чем двумя разными способами можно разбить на кодовые слова.

Рассмотрим самое короткое такое «неоднозначное» $B$ и его различные разбиения на кодовые слова:
![[теория кодирования/images/неделя 01-2.png|w50]]
Точки «верхнего» и «нижнего» разбиений, кроме крайних, все различны, иначе слово $B$ можно было бы укоротить и получить более короткое слово, которое можно неоднозначно разбить на кодовые слова:
![[теория кодирования/images/неделя 01-3.png|w75]]
Среди отрезков слова $B$, концы которых принадлежат *разным* разбиениям, *нет кодовых слов*, иначе $B$ можно было бы укоротить:
![[теория кодирования/images/неделя 01-4.png|w75]]
Минимальные отрезки слова $B$, концы которых принадлежат разным разбиениям, назовем *промежуточными*
![[теория кодирования/images/неделя 01-5.png|w50]]
Обозначим через $w_1,\ldots,w_k$ все промежуточные отрезки.

Через $\beta$ будем обозначать последовательность (возможно пустую) кодовых слов. Имеем:
$$\begin{aligned}
&\exists i,\beta(B_i=\beta w_1)\\
&\exists i,\beta(B_i=w_1\beta w_2)\\
&\vdots\\
&\exists i,j(B_i = w_{k-1}\beta w_k)\\
&\exists i,j(B_i = w_k\beta)
\end{aligned}$$
где $B_i$ — это нижнее кодовое слово (на диаграмме), $\beta$ — последовательность кодовых слов, $w_1$ — первый промежуточный отрезок.

Наоборот, пусть нашлись непустые слова $w_1,\ldots, w_k \in \mathbb{B}^\ast$, кодовые слова $B_{i_1}, \ldots, B_{i_{k+1}}$ и последовательности кодовых слов $\beta_1, \ldots, \beta_{k+1}$ такие, что выполнены соотношения:
$$\begin{aligned}
&B_{i_1} = \beta_1w_1\\
&B_{i_2} = w_1\beta_2 w_2\\
&\vdots\\
&B_{i_{k+1}} = w_k\beta_{k+1}
\end{aligned}$$
Тогда $\beta_1w_1\beta_2w_2\ldots w_{k-1}\beta_k w_k \beta_{k+1}$ декодируется не однозначно.

### критерий однозначности

Код $C=\{B_1,\ldots,B_n\}$ (множество слов) не однозначный тогда и только тогда, когда найдутся:
- непустые слова $w_1,\ldots,w_k\in\mathbb{B}^\ast \backslash C$, которые берут начало из промежуточных отрезков
- кодовые слова $B_{i_1},\ldots,B_{i_{k+1}}$
- последовательности кодовых слов $\beta_1,\ldots,\beta_{k+1}$
такие, что $k\ge1$ и выполнены соотношения
$$\begin{aligned}
&B_{i_1} = \beta_1w_1\\
&B_{i_2} = w_1\beta_2 w_2\\
&\vdots\\
&B_{i_{k+1}} = w_k\beta_{k+1}
\end{aligned}$$
(или $k=0$ и $B_{i_1}=\beta_1$, где $\beta_1$ составлено не менее, чем из двух кодовых слов).

Если $k=0$, то нет непустых слов, есть только некоторое слово $B_{i_1}$ и последовательность кодовых слов $\beta_1$. В этом случае код не является однозначным.

### графовая формулировка

Пусть $C=\{B_1,\ldots,B_n\}$ — код, который нужно проверить.

Строим орграф 
$$G_C=(V,E)$$где 
$$V=\{\varepsilon\}\cup\{\text{слова из } \mathbb{B}^\ast\backslash C\text{, являющиеся началами и концами кодовых слов}\}$$
Промежуточные отрезки — это специальные отрезки в неоднозначном слове, у которых концы являются концами в разных разбиениях: в верхнем и нижнем. То есть отрезок одновременно попадает в конец какого-то слова сверху и в конец какого-то кодового слова снизу. То есть $\{\text{слова из } \mathbb{B}^\ast\backslash C\text{, являющиеся началами и концами кодовых слов}\}$ — это потенциально все слова в кодовом алфавите, которые имеют шансы стать промежуточными отрезками. Это множество конечно, потому что исходное множество кодовых слов конечно, у каждого слова конечная длина, начал кодовых слов — ограниченное количество.

$\{\varepsilon\}$ — пустое слово, имеющее длину ноль. Конкатенация пустого слова с любым другим равна этому другому слову.

Дуга будет проведена между парой вершин (вершина — это слово)
$$E=\big\{(\alpha',\alpha'')|\exists\beta\in C^\ast\big(\alpha'\beta\alpha''\in C \text{ и } (\beta\ne\varepsilon \text{ или }\varepsilon\notin\{\alpha',\alpha''\})\big)\big\}$$
$C^\ast$ — это множество последовательностей, у которых каждый элемент — это кодовое слово.

То есть, должна найтись последовательность кодовых слов такая, что кодовым является слово, начинающееся с $\alpha'$, в середине которого находится $\beta$, заканчиваться слово должно на $\alpha''$, и при этом должно быть выполнено следующее: либо эта последовательность $\beta$ непустая, либо $\alpha'$ и $\alpha''$ — непустые.

Как только построен такой граф, можно проверить однозначность кода, проверив, есть ли в графе ориентированный цикл, проходящий через вершину $\varepsilon$. Код $C$ однозначный $\Leftrightarrow$ в $G_C$ нет орцикла через вершину $\varepsilon$.

### оценка длины неоднозначного слова

Оценить количество вершин можно следующим образом:
$$|V|\le1+\sum_{B\in C}(|B|-1)\le|C|\cdot\max_{B\in C}|B|$$
здесь 1 — это вершина $\varepsilon$, кодовых слов $B\in C$ ограниченное число, $(|B| -1)$ — это количество вариантов выбрать начальное слово из слова $B$. Если перебрать все начала каждого кодового слова, то всего этих начал окажется $\sum_{B\in C}(|B|-1)$.

Оценить сверху количество вершин можно взяв количество всех слов в коде $|C|$ умноженное на максимальную длину кодового слова $\max_{B\in C}|B|$.

Если в графе $G_C$ есть цикл через $\varepsilon$, который посещал вершины графа более одного раза, то можно этот цикл преобразовать, убрав повторения, так, что получится цикл в том же графе $G_C$ и его длина будет не больше, чем количество вершин графа
$$|C|\cdot\max_{B\in C}|B|$$
Рассмотрим соответствующее этому циклу неоднозначно декодируемое слово
$$W_{\text{неодн.}}=\beta_1w_1\beta_2w_2\ldots w_{k-1}\beta_kw_k\beta_{k+1}$$
Можно взять каждую пару, идущих подряд последовательностей $\beta_i$ и промежуточного отрезка $w_i$ и заметить, что каждая такая пара целиком помещается в каком-то кодовом слове. Отсюда следует, что длина этой пары не превосходит максимального размера кодового слова:
$$|\beta_iw_i|\le\max_{B\in C}|B|$$
Таким образом, можно разбить это $W_{\text{неодн.}}$ на пары, каждую пару разместить в каком-то кодовом слове. В итоге получится, что общая длина не превосходит количества пар $(k+1)$ умноженного на максимальную длину каждой пары (максимальный размер кодового слова). Тогда можно получить оценку на длину:
$$|W_{\text{неодн.}}|\le(k+1)\cdot \max_{B\in C}|B|\le |C|\cdot\bigg(\max_{B\in C}|B|\bigg)^2$$
### теорема Маркова

Если $C$ — неоднозначный код, длины слов которого не больше $l$, то найдется «неоднозначное» слово длины не более $|C|\cdot l^2$.

## задача построения кода с минимальной избыточностью

### коды с минимальной избыточностью

- в английском языке буква e встречается примерно в 180 раз чаще, чем z
- если хотим уменьшить объем памяти для хранения текста, естественно кодировать частые буквы короткими словами

Пусть в кодируемых сообщениях символы $a_1,\ldots, a_n$ встречаются с частотами $p_1, \ldots, p_n$ соответственно. Считаем $\sum_{p_i}=1$ и $\forall i \ p_i>0$. 

Пусть $\varphi(a_i)=B_i$.

Рассмотрим произвольное сообщение в естественном алфавите $A \in \mathbb{A}^\ast$.

Каждый из символов $a_i$ встретится в $A$ примерно $|A|\cdot p_i$ (число всех символов умноженное на частоту, с которой встречается символ $a_i$) раз
$$|\varphi(A)|\approx\sum_i|A|\cdot p_i \cdot|B_i|= |A|\cdot\sum_i p_i\cdot|B_i|$$
то есть происходит суммирование количества раз, которое каждый символ $a_i$ встречается в слове умноженного на длину кодового слова $|B_i|$.

Получается, что длина закодированных данных в $\sum_i p_i\cdot|B_i|$ раз больше длины исходных данных.

**Задача построения кода с минимальной избыточностью:**

По заданным $p_1, \ldots, p_n$ построить (однозначно декодирумый) код $B_1, \ldots, B_n \in \mathbb{B}^\ast$ с минимальным коэффициентом избыточности.

Такой код называется *кодом с минимальной избыточностью для набора частот* $p_1,\ldots,p_n$.

## теорема Крафта-Макмиллана

Пусть $l_1,\ldots,l_n$ — длины слов однозначного кода в алфавите $\mathbb{B}$, где $|\mathbb{B}|=q$.
Тогда выполнено неравенство
$$\sum_{i=1}^nq^{-l_i}\le1$$

**доказательство:**

Рассмотрим однозначный код $B_1,\ldots,B_n$ в $q$-значном алфавите, длина $i$-го кодового слова $|B_i|=l_i$

Пусть есть параметр $t \in \mathbb{N}$. Рассмотрим сумму из утверждения, возведенную в степень $t$
$$\bigg(\sum_{i=1}^nq^{-l_i}\le1\bigg)^t=\sum_{1\le i_1,\ldots,i_t\le n}q^{-(l_{i_1}+\ldots+l_{i_t})}=\sum_{i=1}^Ls_lq^{-l}$$
Степень не может быть меньше 1, а сверху можно оценить величиной $L\le t\cdot \max_i|B_i|$.

$s_l$ — количество наборов $(i_1, \ldots, i_t)$, таких, что $l_{i_1}+\ldots+l_{i_t}=l$

Перепишем в виде мощности множеств:
$$s_l=|S_l|, \text{ где } S_l=\big\{(i_1,\ldots,i_t)|l_{i_1}+\ldots+l_{i_t}=l\big\}$$
$S_l$ — это множество всех наборов индексов таких, что сумма соответствующих чисел равна $l$.

Множество индексов $(i_1,\ldots,i_t)\in S_l$ тогда, когда $l_{i_1}+\ldots+l_{i_t}=l$

Сопоставим такому набору индексов слово в кодовом алфавите
$$(i_1,\ldots,i_t)\in S_l\rightarrow B_{i_1}\ldots B_{i_t}\in\mathbb{B}^\ast$$
Разным наборам $S_l$ соответствуют разные слова.

Код однозначный, значит не существует такого слова в кодовом алфавите, которое по-разному может быть разбито на кодовые слова. То есть это преобразование является инъекцией из множества $S_l$ во множество всех слов длины $l$ в кодовом алфавите. Отсюда следует оценка $s_l \le q^l$, так как мощность множества, которое инъектируется, не больше, чем мощность множества, в которое инъекция отображает. Тогда
$$\bigg(\sum_{i=1}^nq^{-l_i}\bigg)^t=\sum_{i=1}^Ls_lq^{-l}\le\sum_{i=1}^L1=L$$
Получили, что для любого $t\in \mathbb{N}$ выполнено
$$\sum_{i=1}^nq^{-l_i}\le\bigg(t\cdot\max_i l_i\bigg)^{1/t}$$
Устремляя $t$ к бесконечности, получаем
$$\sum_{i=1}^nq^{-l_i}\le 1$$
## cуществование префиксных кодов с заданными длинами слова

### теорема о существовании префиксных кодов

Пусть натуральные числа $l_1,\ldots, l_n$ и $q$ таковы, что
$$\sum_{i=1}^nq^{-l_i}\le 1$$
Тогда существует такой префиксный код $B_1, \ldots B_n$ в $q$-значном алфавите, такой, что $|B_i|=l_i$ для каждого $i$.

**доказательство:**

Пусть среди $l_1,\ldots, l_n$ всего $m$ различных, и $l_1<\ldots<l_m$.

Для того, чтобы не потерять информацию об исходном наборе длин, введем величины. Для $j\in [1,m]$ положим $n_j := \big|\{i\in[1, n]|l_i=l_j\}\big|$. 

То есть, $n_j$ — это мощность множества индексов $i$ таких, что длина $l_i$ совпадает с $l_j$. Другими словами, это количество чисел в исходном наборе длин $l_1,\ldots, l_n$, которые совпадают с $l_j$.

Из условия теоремы следует:
$$\sum_{j=1}^mn_jq^{-l_j}\le 1$$
Заменим $m$ на число $k\in[1,m]$. Если взять в сумме первые $k$ слагаемых, то они также в сумме не будут превосходить 1. Домножим обе части неравенства на $q^{l_k}$:
$$q^{l_k}\ge\sum_{j=1}^k n_jq^{l_k-l_j}$$
В этой сумме возьмем отдельно последнее слагаемое, когда $j=k$. В этом случае $q^{l_k-l_j}=q^0=1$:
$$q^{l_k}\ge\sum_{j=1}^k n_jq^{l_k-l_j}=n_k+\sum_{j=1}^{k-1}n_jq^{l_k-l_j}$$
следовательно, для любого $k\in[1,m]$:
$$n_k\le q^{l_k}-\sum_{j=1}^{k-1}n_jq^{l_k-l_j}$$
Начнем строить код. Будем набирать слова в префиксный код по возрастанию длин:
- выбирая $n_1$ слов наименьшей длины $l_1$
- затем $n_2$ слов длины $l_2$
- и т. д.

Пусть взяты слова с длинами $l_1,\ldots,l_{k-1}$. Пусть выполнен $k-1$ шаг и теперь $k$-й шаг. У нас есть множество всех слов, из которых мы выбираем. На текущем шаге выбираем слова длины $l_k$. Таких слов $q^{l_k}$. 

Так как код префиксный, начало слов длины $l_k$ не должно совпадать со словами из предыдущих шагов. Таких запретных слов $n_1q^{l_k-l_1}+\ldots+n_{k-1}q^{l_k-l_{k-1}}$.

То есть, количество слов $n_k$, которые необходимо набрать на $k$-м шаге, не превосходит разницы между количеством слов $q^{l_k}$ длины $l_k$ минус количество запретов. 

Это означает, что точно существует возможность выбрать требуемое количество слов.

## универсальность префиксных кодов

Для любого однозначного кода существует *префиксный* код в *том же* алфавите и с *теми же* длинами кодовых слов.

Берем исходный код в $q$-ичном алфавите со словами $B_1, \ldots, B_n$ с длинами $l_1, \ldots, l_n$. Раз этот код однозначный, значит для него выполнено неравенство Крафта-Макмиллана
$$\sum_{i=1}^nq^{-l_i}\le1$$
По этим параметрам можно построить префиксный код $B_1',\ldots, B_n'$.

## лемма о монотонности длин

Если $B_1,\ldots,B_n$ — код с минимальной избыточностью для набора частот $p_1,\ldots,p_n$, то
$$\forall i,j \ \big(p_i>p_j\Rightarrow|B_i|\le|B_j|\big)$$

То есть, большей частоте соответствует меньшее по длине кодовое слово.

**доказательство:**

Иначе, поменяв местами $B_j$ и $B_i$ местами, получили бы код с коэффициентом избыточности:
$$\sum_{i=1}^np_i|B_i|-(p_i-p_j)(|B_i|-|B_j|)<\sum_{i=1}^np_i|B_i|$$
а это противоречит тому, что исходный код был кодом с минимальной избыточностью.

## теорема Хаффмана о редукции

Пусть $p_1\ge\ldots\ge p_{n-1}\ge p_n$ и $p:=p_{n-1}+p_n$.

Если $B_1, \ldots, B_{n-2}, B\in\{0,1\}^\ast$ — префиксный код с минимальной избыточностью для частот $p_1, \ldots, p_{n-2}, p$, то $B_1, \ldots, B_{n-2}, B0, B1$ — префиксный код с минимальной избыточностью для частот  $p_1, \ldots, p_n$.

**доказательство:**

Пусть коэффициент избыточности укороченного кода $B_1, \ldots, B_{n-2}, B$ для укороченного набора частот $p_1, \ldots, p_{n-2}, p$ равен $k$.

Коэффициент избыточности кода $B_1, \ldots, B_{n-2}, B0, B1$ для нормального набора частот $p_1, \ldots, p_n$ равен по определению
$$\sum_{i=1}^{n-2}p_i|B_i|+(p_{n-1}+p_n)(|B|+1)$$
так как $(p_{n-1}+p_n)=p$ исходную сумму можно переписать как
$$\sum_{i=1}^{n-2}p_i|B_i|+p|B|+p=k+p$$
Где $\sum_{i=1}^{n-2}p_i|B_i|+p|B|$ — это коэффициент избыточности кода $B_1, \ldots, B_{n-2}, B$  для набора частот $p_1, \ldots, p_{n-2}, p$, который по условию равен $k$.

Предположим, что код $B_1, \ldots, B_{n-2}, B0, B1$ не является кодом с минимальной избыточностью для своего набора частот и нашелся какой-то лучший код с длинами слов $B_1',\ldots,B_n'$ коэффициент избыточности которого относительно набора частот $p_1, \ldots, p_n$ меньше, чем $k+p$
$$k'<k+p$$
Без ограничения общности будем считать код $\{B_i'\}^n_{i=1}$ префиксным для набора частот $p_1, \ldots, p_n$.

Так как частоты упорядочены $p_1\ge\ldots \ge p_n$, то соответствующие длины слов упорядочены противоположным образом $|B_1'|\le\ldots\le|B_n'|$.

Пусть слово $B_n'$ получается дописыванием нуля к некоторому слову $B'$: $B_n'=B'0$, тогда

- мы знаем, что $B'$ не является кодовым словом $B'\notin \{B_i'\}^n_{i=1}$
- $B'$ точно является префиксом какого-то из слов $B_1',\ldots,B_{n-1}'$

Без ограничения общности будем считать, что слова занумерованы так, что $B_{n-1}'=B'1$. Тогда код $B_1',\ldots, B_{n-2}', B'$ — префиксный.

Так как длина $B_1',\ldots,B_{n-2}'$ равна $$\sum_{i=1}^{n-2}p_i|B_i'|$$$B'$ равна
$$p|B'|=(p_{n-1}+p_n)|B'|$$
то коэффициент избыточности $B_1',\ldots,B_{n-2}',B'$ для набора частот $p_1,\ldots,p_{n-2},p$ равен их сумме
$$(p_{n-1}+p_n)|B'|+\sum_{i=1}^{n-2}p_i|B_i'|$$
так как длина слов $|B_{n-1}'|$ и $|B_n'|$ на 1 больше, чем длина слова $|B'|$
$$\begin{aligned}
p_{n-1}|B'|+p_n|B'| &= p_{n-1}(B'1-1)+p_n(B'1-1)=\\
&=p_{n-1}|B_{n-1}'|+p_n|B_n'|-(p_{n-1}+p_n)
\end{aligned}$$
сумму можно переписать как
$$(p_{n-1}+p_n)|B'|+\sum_{i=1}^{n-2}p_i|B_i'|=\sum_{i=1}^np_i|B_i'|-(p_{n-1}+p_n)=k'-p<k$$
Это противоречие с тем, что код $B_1,\ldots,B_{n-2},B$ является кодом с минимальной избыточностью для частот $p_1,\ldots,p_{n-2},p$.

## о задаче исправления ошибок

Основные требования к кодам:
- **Однозначность** — обязательное требование. Есть критерий, алгоритм проверки.
- **Минимальная избыточность**. Есть алгоритм построения для произвольно заданного набора частот.
- **Устойчивость к ошибкам**. Возможность расшифровать закодированное сообщение даже при возникновении ошибок при его передаче.

Естественный язык весьма устойчив к ошибкам:
«Веть ву мЖте прчтттть эт ткст п поняц го!»

Причины:
- избыточность: гласные
- разреженность: «вблизи» слов обычно нет других слов — если есть, то ошибки исправляются тяжело: *чемодан зарыт* и *чемодан закрыт*

Основная модель канала связи:
![[теория кодирования/images/неделя 01-6.png|w80]]
