# дискретное и абсолютно непрерывные распределения

*Теорема*
Пусть $f$ обладает свойствами 1, 2 и 3, тогда найдется такой случайный вектор $\xi$ такой, что $f$ совпадает с функцией распределения случайного вектора $\xi$
$$f=F_\xi$$

Эти свойства однозначно задают функцию распределения $F_\xi$.

Посчитать вероятность — это и есть найти значение распределения для некоторого множества.

Допустим, есть случайный вектор $\xi$, есть функция, которая $\mathbb{R}^n\to\mathbb{R}^k$ и является борелевской, и есть борелевское множество $B\in B(\mathbb{R}^k)$. Задача, найти вероятность того, что $P(f(\xi) \in B)$. 

Это то же самое, что найти вероятность того, что $P(\xi \in f^{-1}(B))$, поэтому это не что иное, как значение распределения $P_\xi$ в точке $f^{-1}(B)$.


Распределение $P_\xi$ дискретно, если существует не более, чем счетное множество $x$, такое, что 
$$P_{\xi}(x)=1$$

Распределение $P_\xi$ абсолютно непрерывно, если существует такая функция $p_\xi \ge 0$ такая, что для любого $x \in \mathbb{R}^n$ выполнено 
$$F_\xi(x)=\int_{-\infty}^{x_1}\ldots\int_{-\infty}^{x_n}p_\xi(x)dx_1 \ldots dx_n$$

## пример дискретного распределения

Пусть есть монетка, которая подбрасывается три раза. Пусть решка — это 1, орел — 0. Пусть подбрасывания не зависят от предыдущих. Тогда случайный вектор состоит из трех компонент
$$\xi=(\xi_1,\xi_2,\xi_3)$$
а множество $X$, на котором сосредоточено распределение
$$X=\{0,1\}^3$$
то есть, это множество трёхмерных векторов, координаты которых являются 0 или 1. У каждой точки вероятность равна $1/8$
$$\forall x \in X \ P_\xi(x)=\frac{1}{8}$$
Для любого $x$ , такого, что $x_1<0,x_2<0,x_3<0$
$$F_\xi(x)=0$$
до этой точки других точек нет. Если существует хотя бы одна координата, такая, что $x_i<0$, то $F_\xi(x)=0$, потому что меньших $x$, попадающих в множество $X$ не существует.

Например, можно посчитать $F_\xi(\frac{1}{2}, \frac{3}{2}, \frac{1}{2})$. Следует понять, сколько сюда попадает точек множества $X$. Например, попадает $(0,0,0)$ и $(0,1,0)$, не попадает $(0,0,1)$. Раз попадает всего две точки, то следует два раза сложить $1/8$ и получается, что вероятность будет равна $1/4$
$$F_\xi\bigg(\frac{1}{2}, \frac{3}{2}, \frac{1}{2}\bigg)=\frac{1}{4}$$
## пример абсолютно непрерывного распределения

Пусть $P_\xi$ — это равномерное распределение в квадрате со стороной 1. Тогда $P_\xi$ от множества $A$ — это площадь пересечения множества $A$ и отрезка $[0,1]$:
$$P_\xi(A)=\bigg|A\cap[0,1]^2\bigg|$$
У абсолютно непрерывного распределения должна быть плотность, тогда
$$p_\xi(x)=I(x\in[0,1])$$
тогда функция распределения
$$F_\xi(x)=\int_{-\infty}^{x_1}\int_{-\infty}^{x_2}P_\xi(x_1,x_2)dx_1dx_2=$$
Так как $P_\xi$ — это конкретная функция, интеграл можно вычислить. Если $x_1$, либо $x_2$ отрицательны, то интеграл равен нулю. Если положительны, то пересечение будет представлять собой прямоугольник, где $x_1<1, x_2<1$. Если один из них больше единицы, то соответствующая координата убирается и остается только та, что меньше единицы.
$$=x_1x_2I(0<x_1<1, 0<x_2<1)+x_1 I(0<x_1<1, x_2 \ge 1)+x_2 I(x_1\ge1, 0<x_2<1)+1I(x_1\ge1, x_2\ge1)$$

## вычисление вероятности в абсолютно непрерывном случае

Задача состоит в том, чтобы посчитать вероятность
$$P\big(f(\xi)\in B\big)=P\big(\xi\in f^{-1}(B)\big)=P_\xi\big(f^{-1}(B)\big)$$
Так как распределение абсолютно непрерывное, это значит, что у $\xi$ есть плотность.
$$P_\xi(A)=\int_A p_\xi(x)dx_1\ldots dx_n$$
Тогда вероятность есть не что иное, как
$$=\int_{f^{-1}(B)}p_\xi(x)dx$$

Например, есть такая плотность
$$p_\xi(x_1,x_2,x_3)=I(0\le x_1,x_2\le 1)e^{-x_3}I(x_3\ge0)$$
это произведение трех плотностей. Посчитаем вероятность того, что $x_1+x_2-x_3<0$
	$$P(x_1+x_2-x_3<0)=\int_{u_1+u_2-u_3<0}p_\xi(u)du=$$
$x_1$ и $x_2$ лежат от нуля до единицы, а $x_3$ от нуля до бесконечности
$$\int_{u_1+u_2}^\infty e^{-x_3}dx=e^{-u_1-u_2}$$
тогда
$$=\int_0^{x_1}\int_0^{x_2}\int_{u_1+u_2}^\infty p_\xi(u)du=\int_0^{x_1}\int_0^{x_2}e^{-u_1-u_2}du_1du_2=\int_0^{x_1}(1-e^{-x_2})e^{-u_1}du_1=(1-e^{-x_2})(1-e^{-x_1})=$$
примем $x_1=x_2=1$
$$=\bigg(1-\frac{1}{e}\bigg)^2$$

## распределение вектора из независимых случайных величин

Пусть $\xi=(\xi_1,\ldots,\xi_n)$ — независимые случайные величины.

Распределение — это мера борелевского множества из $\mathbb{R}^n$, которое равно мере прообраза.

Возьмем в качестве прообраза декартово произведение борелевских множеств в $\mathbb{R}$
$$P_\xi(B_1\times\ldots\times B_n)=P(\xi_1\in B_1,\ldots,\xi_n\in B_n)=$$
так как величины независимы
$$=P(\xi_1\in B_1)\times\ldots\times(\xi_n\in B_n)$$
Можно сделать вывод о функции распределения
$$F_\xi(x_1,\ldots,x_n)=F_{\xi_1}(x_1)\times\ldots\times F_{x_n}(x_n)$$
***Теорема***
Если функция распределения вектора равна функции распредления компонент, тогда случайные величины независимы.


Если $P_\xi$  абсолютно непрерывна, а $F_\xi$ — дифференцируема, то тогда плотность — это производная функции распределения
$$p_\xi=\frac{\partial^n}{\partial x_1\ldots\partial x_n}F_\xi$$
Плотность будет равна произведению плотностей, так как функция дифференцируема
$$p_\xi=p_{\xi_1}\times\ldots\times p_{\xi_n}$$

## характеристическая функция случайного вектора

Характеристической функцией случайного вектора $\xi$ называется функция $\varphi_\xi$
$$\varphi_\xi:\mathbb{R}^n\to\mathbb{C}$$
по следующему правилу
$$\varphi_\xi(x_1,\ldots,x_n)=Ee^{i\langle x,\xi\rangle}$$
где
$$\langle x, \xi \rangle=x_1\xi_1+\ldots+x_n\xi_n$$
Пусть $\xi$ имеет нормальное распределение
$$\xi\sim \mathcal{N}(0,1)$$
тогда
$$\varphi_\xi(x)=Ee^{i\xi x}=\int_{-\infty}^{+\infty}e^{itx}p(t)dt=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}e^{itx}e^{-\frac{t^2}{2}}dt=$$
занесем все под одну экспоненту
$$=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}e^{-\frac{(t-ix)^2}{2}}e^{-\frac{x^2}{2}}dt=e^{-\frac{x^2}{2}}$$
В общем случае
$$\xi \sim \mathcal{N}(a,\sigma^2)$$
тогда
$$\varphi_\xi(x)=e^{iax-\frac{1}{2}\sigma^2x^2}$$

## гауссовский вектор

$\xi$ — гауссовский вектор с параметрами $(a, \Sigma)$ (где $a$ — $n$-мерный вектор, а $\Sigma$ — квадратная матрица размера $n\times n$), если характеристическая функция равна
$$\varphi_\xi=e^{i\langle a, x\rangle-\frac{1}{2}\langle\Sigma x,x\rangle}$$
В одномерном случае $a$ превращается в матожидание, а $\Sigma$ — в дисперсию.

### свойства

1. $a$ — это вектор математических ожиданий
$$\forall i \in \{1,\ldots, n\} E\xi_i=a_i$$
2. $\Sigma$  — это матрица ковариаций
$$\forall i,j\in\{1,\ldots, n\}\Sigma_{i,j}=\text{cov}(\xi_i,\xi_j) $$
Из этого следует, что матрица $\Sigma$ симметрична и неотрицательно определена, то есть $\forall x: \langle \Sigma x, x\rangle \ge 0$. 

3. Компоненты гауссовского вектора независимы тогда и только тогда, когда их ковариации равны нулю. 

### эквивалентные определения

Для любых неотрицательных $\lambda_1, \ldots, \lambda_n$ сумма $\lambda_1\xi_1+\ldots +\lambda_n\xi_n$ — это нормальная случайная величина. Вырожденный случай тоже подходит (если получилась константа).

Найдется такой вектор $\eta=(\eta_1, \ldots, \eta_m)^T$, что его компоненты — это стандартные нормальные **независимые** случайные величины. Найдется такая матрица $A$ и вектор $b$, что $\xi$ в точности равно $A\eta + b$. То есть $\xi$ — это линейное преобразование со смещением вектора, составленного из независимых стандартных нормальных случайных величин.

## многомерная центральная предельная теорема

Пусть есть счетная последовательность независимых в совокупности одинаково распределенных случайных векторов с векторами математических ожиданий $a$ и матрицами ковариаций $\Sigma$ (векторы одинаково распределены, поэтому матрицы одинаковы), тогда 
$$\frac{F_{\xi_1+\ldots+\xi_n-na}(x)}{\sqrt{n}}\to F_\eta(x), \forall x\in \mathbb{R}^n$$
где
$$\eta \sim \mathcal{N}(0, \Sigma)$$
распределение нормированной суммы сходится к многомерному нормальному распределению.

## неотрицательная определенность матрицы ковариаций

Пусть есть произвольный случайный $n$-мерный вектор $\xi=(\xi_1, \ldots, \xi_n)$ с матрицей ковариаций $\Sigma=(\sigma_{ij}) \ i,j \in \{1, n\}$, все элементы которой конечны
$$\sigma_{ij}=\text{cov}(\xi_i, \xi_j)$$
Докажем, что для любого вектора строки $x=(x_1, \ldots, x_n)\in \mathbb{R}^n$ верно, что $x\Sigma x^T\ge0$.

Дисперсия
$$D(x\xi^T)=D(x_1\xi_1+\ldots+x_n\xi_n)= \text{cov}(x_1\xi_1+\ldots+x_n\xi_n,x_1\xi_1+\ldots+x_n\xi_n)$$
по свойству билинейности ковариации
$$=\sum_{i=1}^n\sum_{j=1}^nx_ix_j\text{cov}(\xi_i,\xi_j)=\sum_{i=1}^n\sum_{j=1}^nx_i\sigma_{ij}x_j=$$
а это и есть
$$=x\Sigma x^T$$
$\Sigma x^T$ — это вектор столбец, у которого на первом месте стоит первая строка матрицы $\Sigma$, умноженная на вектор $x^T$
$$\Sigma x^T= \begin{pmatrix}
\sigma_{11}x_1+\ldots +\sigma_{1n}x_n\\
\vdots \\
\sigma_{n1}x_1+\ldots +\sigma_{nn}x_n\\
\end{pmatrix}$$
если это умножить слева на строку $x$
$$x\Sigma x^T=\sigma_{11}x_1^2+\ldots+\sigma_{1n}x_1x_n+\ldots+\sigma_{n1}x_1x_n+\ldots+\sigma_{nn}x_n^2$$

## нахождение матрицы ковариаций

Пусть есть случайный вектор $(\xi, \eta)$, у которого известна совместная плотность
$$p_{(\xi,\eta)}=\frac{1}{\frac{\pi}{4}}I(x^2y^2<1, x>0, y>0)$$
Необходимо найти матрицу ковариаций
$$\Sigma=\begin{pmatrix}
D\xi & \text{cov}(\xi,\eta) \\
\text{cov}(\xi,\eta) & D\eta
\end{pmatrix}$$
матожидание $E\xi\eta$
$$E\xi\eta=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}xy p_{(\xi\eta)}(x,y)dxdy=$$
по $x$ будем интегрировать от 0 до 1, по $y$ от 0 до $\sqrt{1-x^2}$
$$\int_{0}^{1}\int_{0}^{\sqrt{1-x^2}}xydxdy=\int_0^1x\frac{1-x^2}{2}dx=\frac{1}{4}-\frac{1}{8}=\frac{1}{8}$$
математическое ожидание $\xi$
$$E\xi=\int_0^1\int_0^{\sqrt{1-x^2}}xdxdy=\int_0^1x\sqrt{1-x^2}dx=$$
$$=\int_0^1\sqrt{1-x^2}d\bigg(\frac{x^2}{2}\bigg)==-\frac{1}{2}\cdot\frac{2}{3}(1-x^2)^{\frac{3}{2}}\bigg|_0^1=\frac{1}{3}$$
найдем теперь математическое ожидание $\xi^2$
$$E\xi^2=\int_{0}^{1}\int_{0}^{\sqrt{1-x^2}}x^2dxdy= \int_0^1 x^2\sqrt{1-x^2}dx=|x \sin t|=\int_0^{\frac{\pi}{2}}\sin^2 t \cos^2 tdt=$$
$$=\int_0^{\frac{\pi}{2}}\frac{1-\cos^2 2t}{4}dt=\int_0^{\frac{\pi}{2}}\frac{\frac{1-cos4t}{2}}{4}dt=\frac{1}{8}\int_0^{\frac{\pi}{2}}(1-\cos4t)dt=\frac{\pi}{16}$$
дисперсия $\xi$
$$D\xi=\frac{\pi}{16}-\frac{1}{9}$$
тогда матрица будет
$$\Sigma=\begin{pmatrix}
\frac{\pi}{16}-\frac{1}{9} & \frac{1}{72} \\
\frac{1}{72} & \frac{\pi}{16}-\frac{1}{9}
\end{pmatrix}$$

## эквивалентность определений гауссовского вектора

Возьмем скалярное произведение	$$\langle\lambda,\xi\rangle=\lambda^T\xi=\lambda^T(A\eta + b)=(\lambda^TA)\eta+\lambda^Tb\sim\mathcal{N}(\lambda^Tb,\dots)$$

Мы знаем, что для любого $\lambda\in \mathbb{R}^n$ скалярное произведение $\langle\lambda, \xi\rangle$ имеет нормальное распределение. Пусть оно имеет нормальное распределение с параметрами $\mathcal{N}(a(\lambda),\sigma^2(\lambda))$. 

Понятно, что $a(\lambda)$
$$a(\lambda)=E\langle\lambda,\xi\rangle=\langle\lambda,E\xi\rangle$$
а $\sigma^2$
$$\sigma^2(\lambda)=D\langle\lambda,\xi\rangle=\text{cov}(\lambda_1\xi_1+\ldots+\lambda_n\xi_n, \lambda_1\xi_1+\ldots+\lambda_n\xi_n)=\sum_{i,j}\lambda_i\lambda_j\text{cov}(\xi_i\xi_j)=\lambda^T\Sigma\lambda=\langle\Sigma\lambda,\lambda\rangle$$
характеристическая функция скалярного произведения в точке 1
$$\varphi_{\langle\lambda,\xi\rangle}(1)=e^{iE\langle\lambda,\xi\rangle-\frac{1}{2}\langle\Sigma\lambda,\lambda\rangle}=Ee^{i\langle\lambda,\xi\rangle}=\varphi_\xi(\lambda)$$

## линейное преобразование гауссовского вектора

Возьмем двумерный гауссовский вектор $\xi$ со средним $(2, -3)^T$ и матрицей ковариаций
$$\begin{pmatrix}
1 & -2 \\
-2 & 5
\end{pmatrix}$$
Рассмотрим вектор $\eta$
$$\eta=A\xi+\begin{pmatrix}
0\\
2
\end{pmatrix}$$
где $A$
$$A=\begin{pmatrix}
2 & 0 \\
1 & 1
\end{pmatrix}$$
матожидание $\eta$
$$E\eta=E(A\xi+b)=AE\xi+b=\begin{pmatrix}
2 & 0 \\
1 & 1
\end{pmatrix}\begin{pmatrix}
2 \\
-3
\end{pmatrix}+\begin{pmatrix}
0 \\
2
\end{pmatrix}=\begin{pmatrix}
4 \\
1
\end{pmatrix}$$
осталось найти матрицу ковариаций
$$D\eta=D(A\xi+b)$$
найдем ковариацию
$$\text{cov}\big((A\xi+b)_i, (A\xi+b)_j\big)=\text{cov}(A_i\xi+b_i,A_j\xi+b_j)=$$
$$=\text{cov}(A_i\xi,A_j\xi)=A_i\Sigma A_j^T$$
$$\text{cov}(\eta_1,\eta_2)=(2,0)\begin{pmatrix}
1 & -2 \\
-2 & 5
\end{pmatrix}
\begin{pmatrix}
1 \\
1
\end{pmatrix}=(2,0)\begin{pmatrix}
-1 \\
1
\end{pmatrix}=-2$$
дисперсия
$$D\eta_1=(2,0)\begin{pmatrix}
1 & -2 \\
-2 & 5
\end{pmatrix}
\begin{pmatrix}
2 \\
0
\end{pmatrix}=4$$

$$D\eta_2=(1,1)\begin{pmatrix}
1 & -2 \\
-2 & 5
\end{pmatrix}
\begin{pmatrix}
1 \\
1
\end{pmatrix}=2$$
тогда 
$$\eta\sim\mathcal{N}\bigg(\begin{pmatrix}
4 \\
1
\end{pmatrix}
,\begin{pmatrix}
4 & -2 \\
-2 & 2
\end{pmatrix}\bigg)$$

## люди на эскалаторах

Пусть есть три эскалатора, причем один из них более широкий, нежели остальные. Каждый человек попадает на широкий эскалатор с вероятностью $1/2$ и на каждый из узких с вероятностью $1/4$.

$x_i$ — номер эскалатора, по которому поднялся $i$-й человек. 

$N_j$ — это количество людей, прошедших по $j$-му эскалатору
$$N_j=\sum_{i=1}^n I(x_i=j)$$
Найти $\lim_{n\to\infty}P(N_1<N_2+N_3)$


Заметим, что вектор, составленный из случайных величин $N_1, N_2, N_3$ 
$$\begin{pmatrix}
N_1 \\
N_2 \\
N_3
\end{pmatrix}=\sum_{i=1}^n\begin{pmatrix}
I(x_i=1) \\
I(x_i=2) \\
I(x_i=3)
\end{pmatrix}=\sum_{i=1}^n\xi_i$$
матожидание одного вектора
$$E\xi_i=\bigg(\frac{1}{2},\frac{1}{4},\frac{1}{4}\bigg)$$
матрица ковариаций

$$EI(x_i=1)I(x_i=2)=0$$

$$\Sigma=\begin{pmatrix}
\frac{1}{4} & -\frac{1}{8} & -\frac{1}{8} \\
-\frac{1}{8} & \frac{3}{16} & -\frac{1}{16} \\
-\frac{1}{8} & -\frac{1}{16} & \frac{3}{16}
\end{pmatrix}$$

можно применить ЦПТ
$$\frac{\sum_{i=1}^n\xi_i-n\bigg(\frac{1}{2},\frac{1}{4},\frac{1}{4}\bigg)}{\sqrt{n}}\xrightarrow[]{d}\mathcal{N}(0,\Sigma)$$

Рассмотрим вероятность того, что $P(N_1<N_2+N_3)$. $N_1$ — это сумма первых координат вектора $\xi_i$, а $N_2$ и $N_3$ — это, соответственно, вторая и третья координаты
$$P(N_1<N_2+N_3)=P\bigg(\sum\xi_i^1<\sum\xi_i^2+\sum\xi_i^3\bigg)=$$
вычтем с обеих сторон $n/2$, поделенный на $\sqrt{n}$
$$P\bigg(\frac{\sum\xi_i^1-n/2}{\sqrt{n}}<\frac{\sum\xi_i^2-n/4}{\sqrt{n}}+\frac{\sum\xi_i^3-n/4}{\sqrt{n}}\bigg)=$$

если $\eta_n \xrightarrow[]{d}\eta$, то отсюда следует, что $f(\eta_n)\xrightarrow[]{d}f(\eta)$  (это верно для любых непрерывных функций).

Отсюда получаем, что
$$\eta_n^1-\eta_n^2-\eta_n^3\xrightarrow[]{d}\eta^{(1)}-(\eta^{(2)}+\eta^{(3)})\sim\mathcal{N}(0,\dots)$$
раз среднее равно нулю, то в пределе вероятность будет стремиться к $1/2$.
$$P(\eta_n^1-\eta_n^2-\eta_n^3<0)\xrightarrow[n\to\infty]{}P(\eta^{(1)}-\eta^{(2)}-\eta^{(3)}<0)=\frac{1}{2}$$

