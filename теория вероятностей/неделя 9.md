# Дискретное распределение

Если есть случайная величина $\xi$, которая на своем пространстве элементарных событий принимает, лишь какое-то конечное множество значений
$$\xi:\Omega\rightarrow\{y_1,\ldots,y_k\}$$
Тогда функция распределения определяется вероятностями, с которыми $\xi$ принимает отдельные значения
$$F_\xi(x)=\sum_{y_i,y_i<x}P(\xi=y_i)$$
Самое известное такое распределение
$$\xi\sim\text{Binom}(n,p)$$
у нее вероятность
$$P(\xi=k)=C_n^kp^kq^{n-k}$$

Если $\xi$ принимает бесконечное, но счетное множество значений
$$\xi:\Omega\rightarrow\{y_i\}_{i=1}^\infty$$
$\xi$ — это момент 1-го успеха в схеме бесконечного числа испытаний Бернулли.

Тогда вероятность
$$P(\xi=k)=(1-p)^{k-1}p$$

## Распределение Пуассона

Пуассоновская случайная величина — это величина, которая на своем пространстве элементарных событий, принимает также значение 0.
$$\xi:\Omega\rightarrow\{y_i\}_{i=0}^\infty$$
Вероятность
$$P(\xi=k)=\frac{\lambda^ke^{-\lambda}}{k!}$$
где $\lambda > 0$.

Если вероятность успеха ведет себя как $p=\frac{\lambda}{n}$, то биномиальное распределение хорошо аппроксимируется пуассоновским.

# Абсолютно непрерывные распределения

Пусть $p(x)$ — это некоторая функция, которая принимает неотрицательные значения и обладает тем свойством, что, если проинтегрировать это функцию по всей вещественной прямой, то получится 1. Эта функция называется ***плотностью распределения***.

Случайная величина $\xi$ определенная, как минимум, на континуальном по мощности вероятностном пространстве, называется абсолютно непрерывной, если функция распределения этой случайной величины задается интегралом плотности распределения:
$$F(x)=\int_{-\infty}^xp(t)dt$$
## Равномерное распределение

Равномерное распеределение — это абсолютно непрерывное распределение, плотность которого задается как
$$p(x)=\begin{cases}
\frac{1}{b-a}, x\in[a,b] \\
0,x\notin [a,b]
\end{cases}$$
Если $\xi$ имеет равномерное распределение, то ее функция распределения, это
$$F_\xi(x)=\int_{-\infty}^xp(t)dt$$
С какой вероятностью $\xi$ принимает значение, не превосходящее $x$, если $x\le a$? На этом промежутке интегрируется ноль:
$$F_\xi(x)=0$$
Когда $x$ попадает внутрь отрезка $[a,b]$, тогда 
$$F_\xi(x)=\int_a^x\frac{1}{b-a}dt=\frac{t}{b-a}\bigg|_a^x=\frac{x-a}{b-a}$$
![[probability_09.001.png]]
То есть, вероятность того, что $\xi$ окажется не больше, чем $x$ — это отношение маленького отрезка к длине всего отрезка $[a,b]$.

## Стандартное нормальное распределение

Нормальное распределение (Гауссовское распределение) — это распределение, которое задается в простейшем случае, плотностью:
$$p(x)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}$$
здесь $x$ — любое на вещественной прямой.
$$P\bigg(\frac{\mu_n-np}{\sqrt{npq}}\le x\bigg)\xrightarrow[n\to\infty]{}\int_{-\infty}^{x}p(t)dt$$
То есть предельная теорема Муавра-Лапласса — это утверждение, что функция распределения центрированной и нормированной биномиальной случайной величины при большом числе испытаний крайне похожа на функцию распределения нормальной случайной величины.

На графике плотность выглядит как
![[probability_09.002.png]]

## Общий случай нормального распределения

$$p(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-a)^2}{2\sigma^2}}\ge 0$$
где $\sigma>0, a\in\mathbb{R}$, $\xi \sim N(a,\sigma^2)$ 

## Экспоненциальное распределение

$$\xi\sim Exp(\alpha)$$
плотность
$$p(x)=\begin{cases}
\alpha e^{-\alpha x}, x\ge 0 \\
0, x<0
\end{cases}$$


## χ^2 распределение
Если взять $n$ нормальных стандартных случайных величин
$$\xi_1,\ldots,\xi_n\sim N(0,1)$$
и предположить, что они независимы, то случайная величина
$$\xi_1^2,\ldots,\xi_n^2\sim \chi^2n$$
называется $\chi$-квадрат с $n$ степенями свободы.

## распределение Коши

плотность
$$p(x)=\frac{1}{\pi}\cdot\frac{1}{1+x^2}$$


# Математическое ожидание

Если есть случайная величина $\xi$, то ее математическое ожидание
$$M\xi=\sum_{i=1}^\infty y_iP(\xi=y_i)$$
Для абсолютно непрерывной случайной величины
$$M\xi=\int_{-\infty}^{\infty}yp(y)dy$$


Есть случайная величина $\xi$, есть функция от нее $f(\xi)$, такая, что $f(\xi)$ — это тоже случайная величина
тогда для конечной случайной величины
$$M\big(f(\xi)\big)=\sum_{i=1}^kf(y_i)P(\xi=y_i)$$
для абсолютно непрерывной случайной величины
$$M\big(f(\xi)\big)=\int_{-\infty}^{\infty}f(y)p(y)dy$$
# Момент

$M(\xi^k)$ — $k$-й момент случайной величины.

Если существует $k$-й момент, то существуют все предыдущие.

$k$-й факториальный момент 
$$M_f^k\xi:=M\big(\xi(\xi-1)\ldots(\xi-k+1)\big)$$
# Независимость случайной величины

$\xi$ и $\eta$ — независимы, если
$$P(\xi\le x,\eta\le y)=P(\xi\le x)P(\eta\le y)$$
Левая часть равенства называется функцией совместного распределения случайных величин $\xi$ и $\eta$.
$$F_\xi(\xi,\eta)=F_\xi(x)F_\eta(y)$$
Можно рассмотреть $n$ случайных величин $\xi_1,\ldots,\xi_n$, их независимость в совокупности
$$\forall x_1,\ldots,x_n \ P(\xi\le x_1,\ldots, \xi_n\le x_n)=P(\xi_1=x_1)\ldots P(\xi_n\le x_n)$$
Функция совместного распределения
$$F_{\xi_1,\ldots,\xi_n}(x_1, \ldots,x_n)=F_{\xi_1}(x_1)\ldots F_{\xi_n}(x_n)$$
