\
# два простейших примера цепи Маркова

**Случайная последовательность** — это последовательность случайных величин.

## симметричное случайное блуждание

**Простейшее симметричное случайное блуждание** — это последовательность случайных величин $S_0, S_1, S_2, \ldots$, таких, что $S_0=0$, а $S_n= \xi_1+\ldots+\xi_n$, где задана некоторая последовательность случайных величин $\xi_1, \xi_2, \ldots$, которые независимы и одинаково распределенные величины такие, что их распределение известно:
$$P(\xi_1=1)=P(\xi_1=-1)=\frac{1}{2}$$
Блужданием оно назвается потому, что можно нарисовать его **траекторию**. Под траекторий подразумевается следующий объект: фиксируется $\omega \in \Omega$ и рассматриваются реализации случайной величины в виде бесконечной последовательности $(S_0(\omega), S_1(\omega), \ldots)$. 

Например, можно вычислить, что в момент времени $n$ 
$$P(S_n=k)$$
Для того, чтобы в момент времени $n$ оказаться в точке $k$, необходимо $(n+k)/2$ раз пойти вверх и $(n-k)/2$ — вниз. Чтобы оказаться в $k$, следует выбрать все шаги, в которых движение происходило вверх
$$P(S_n=k)=C_n^{(n+k)/2}p^{(n+k)/2}p^{(n-k)/2}$$
Это все в допущении, что $k$ лежит в отрезке $[-n, n]$ и $k+1$ должно быть четным числом. Иначе вероятность равна нулю.

## ветвящийся процесс

**Ветвящийся процесс** — это последовательность $X_1=1, X_2, X_3, \ldots$,  где
$$X_n=\sum_{i=1}^{X_{n-1}}\xi_{n,i}$$
где $\xi_{n,i}$ — независимые одинаково распределенные и принимающие целые неотрицательные значения случайные величины.

# цепь Маркова

**Цепь Маркова** — это последовательность случайных величин $\xi_0, \xi_1, \xi_2, \ldots$ таких, что они принимают значения в неболее, чем счетном множестве $X$ и для любого натурального момента времени $n$ и для любых чисел $x_0, x_1, \ldots, x_n \in X$ выполнено
$$P(\xi_n=x_n|\xi_{n-1}=x_{n-1},\xi_{n-2}=x_{n-2},\ldots)=P(\xi_n=x_n| \xi_{n-1}=x_{n-1})$$
то есть марковская цепь характеризуется тем, что при фиксированном настоящем, будущее не зависит от прошлого. То есть следующий момент зависит только от текущего.

*Симметричное простейшее случайное блуждание*
$$P(S_n=x_n|S_{n-1}=x_{n-1},\ldots)=\frac{P(S_n=x_n,S_{n-1}=x_{n-1}, \ldots)}{P(S_{n-1}=x_{n-1}, \ldots)}=$$
понятно, что в этом случае значения иксов могут по условию различаться только на единицу.
$$=\frac{P(\xi_n=a_n, \xi_{n-1}=a_{n-1},\ldots)}{P(\xi_{n-1}=a_{n-1}, \ldots)}=P(\xi_n=a_n)$$
где $a_n=x_n-x_{n-1}$

Такую вероятность можно тоже расписать по определению условной вероятности
$$P(S_n=x_n |S_{n-1}=x_{n-1})=\frac{P(S_n=x_n, S_{n-1}=x_{n-1})}{P(S_{n-1}=x_{n-1})}=$$
$$=\frac{P(\xi_n=a_n,S_{n-1}=x_{n-1})}{P(S_{n-1}=x_{n-1})}=P(\xi_n=a_n)$$
тогда симметричное простейшее случайное блуждание — это марковская цепь.

*Ветвящийся процесс*

$$P(X_n=x_n|X_{n-1}=x_{n-1},\ldots)=\frac{P(X_n=x_n,X_{n-1}=x_{n-1},\ldots)}{P(X_{n-1}=x_{n-1},\ldots)}=$$
$$=\frac{P\bigg(\sum_{i=1}^{x_{n-1}}\xi_{n,i}=x_n, X_{n-1}=x_{n-1}\bigg)}{P(X_{n-1}=x_{n-1},\ldots)}=P\bigg(\sum_{i=1}^{x_{n-1}}\xi_{n,i}=x_n\bigg)$$
дальнейшее рассуждение будет аналогичным тому, что было в случайном блуждании. Поэтому ветвящийся процесс — тоже цепь Маркова.

# эквивалентное определение

Если $\xi_n$ — цепь Маркова, то для любых моментов времени $n > k_1 > \ldots >k_m\ge 0$ и для любых значений цепи Маркова $x_n, y_1, \ldots, y_m \in X$ выполнено 
$$P(\xi_n=x_n|\xi_{k_1}=y_1,\ldots, \xi_{k_m}=y_m)=P(\xi_n=x_n|\xi_{k_1}=y_1)$$
***Доказательство***

$K_1=n-1$
Нужно доказать, что 
$$P(\xi_n=x_n|\xi_{n-1}=y_{1},\xi_{K_2}=y_2, \ldots)=$$
Распишем по определению
$$=\frac{P(\xi_n=x_n,\xi_{n-1}=y_{1},\xi_{K_2}=y_2, \ldots)}{P(\xi_{n-1}=y_{1},\xi_{K_2}=y_2, \ldots)}=$$
посмотрим на все моменты времени, которых нет в последовательности $\xi_{n-1}=y_{1},\xi_{K_2}=y_2, \ldots$,  так как в ней какие-то моменты времени могут быть пропущены. Просуммируем по всем возможным значениям цепи Маркова в это время.
$$=\sum_{x_{n-2},\ldots\in X}\frac{P(\xi_n=x_n,\xi_{n-1}=y_{1}, \xi_{n-2}=x_{n-2}, \ldots)}{P(\xi_{n-1}=y_{1},\xi_{K_2}=y_2, \ldots)}=$$
$$=\sum_{x_{n-2},\ldots\in X}\frac{P(\xi_n=x_n,\xi_{n-1}=y_{1}, \xi_{n-2}=x_{n-2}, \ldots)}{P(\xi_{n-1}=y_1,\xi_{n-2}=x_{n-2,\ldots})}
\cdot
\frac{P(\xi_{n-1}=y_1,\xi_{n-2}=x_{n-2,\ldots})}{P(\xi_{n-1}=y_{1},\xi_{K_2}=y_2, \ldots)}=$$
$$=\sum_{x_{n-2},\ldots\in X}P(\xi_n=x_n|\xi_{n-1}=y_1)\cdot
\frac{P(\xi_{n-1}=y_1,\xi_{n-2}=x_{n-2,\ldots})}{P(\xi_{n-1}=y_{1},\xi_{K_2}=y_2, \ldots)}=$$
$$=P(\xi_n=x_n|\xi_{n-1}=y_1)\sum_{x_{n-2},\ldots\in X}
\frac{P(\xi_{n-1}=y_1,\xi_{n-2}=x_{n-2,\ldots})}{P(\xi_{n-1}=y_{1},\xi_{K_2}=y_2, \ldots)}=$$
$$=P(\xi_n=x_n|\xi_{n-1}=y_1)$$

Предположим, что для любых $n$ и для любых $K_1, \ldots, K_m$ таких, что  $n-K_1\le i - 1$
Для любых $x_n, y_1, \ldots, y_m\in X$ верно, что 
$$P(\xi_n=x_n|\xi_{K_1}=y_1,\ldots,\xi_{K_m}=y_m)=P(\xi_n=x_n|\xi_{K_1}=y_1)$$
Пусть $n-K_1=i$
$$P(\xi_n=x_n|\xi_{K_1}=y_1,\ldots,\xi_{K_m}=y_m)=$$
$$=\frac{P(\xi_n=x_n,\xi_{K_1}=y_1,\ldots,\xi_{K_m}=y_m)}{P(\xi_{K_1}=y_1,\ldots,\xi_{K_m}=y_m)}=$$
добавим момент времени $n-1$
$$=\sum_{x_{n-1}\in X}\frac{P(\xi_n=x_n,\xi_{n-1}=x_{n-1},\xi_{K_1}=y_1,\ldots,\xi_{K_m}=y_m)}{P(\xi_{K_1}=y_1,\ldots,\xi_{K_m}=y_m)}=$$
$$=\sum_{x_{n-1}\in X}
\frac{P(\xi_n=x_n,\xi_{n-1}=x_{n-1},\xi_{K_1}=y_1,\ldots,\xi_{K_m}=y_m)}{P(\xi_{n-1}=x_{n-1}, \ldots)}
\cdot
\frac{P(\xi_{n-1}=x_{n-1}, \ldots)}{P(\xi_{K_1}=y_1,\ldots,\xi_{K_m}=y_m)}=$$
$$=\sum_{x_{n-1}\in X}P(\xi_n=x_n|\xi_{n-1}=x_{n-1})P(\xi_{n-1}=x_{n-1}|\xi_{K_1}=x_1)=$$
$$=\sum_{x_{n-1}\in X}P(\xi_n=x_n|\xi_{n-1}=x_{n-1},\xi_{K_1}=x_1)P(\xi_{n-1}=x_{n-1}|\xi_{K_1}=x_1)=$$
$$=\sum_{x_{n-1}\in X}\frac{P(\xi_n=x_n,\xi_{n-1}=x_{n-1},\xi_{K_1}=x_1)}{P(\xi_{K_1}=x_1)}=$$
$$=\frac{1}{P(\xi_{K_1}=x_1)}\sum_{x_{n-1}\in X}P(\xi_n=x_n,\xi_{n-1}=x_{n-1},\xi_{K_1}=x_1)=$$
$$=\frac{P(\xi_n=x_n,\xi_{K_1}=x_1)}{P(\xi_{K_1}=x_1)}=P(\xi_n=x_n|\xi_{K_1}=x_1)$$

# переходные вероятности и распределение

Множество $X$, в котором цепь Маркова принимает значение, называется **фазовое пространство** или **пространство состояний**.

Вероятности $p_{i,j}(k, n)= P(\xi_n=j|\xi_k=i)$ называются **переходными**.

Вероятность $\pi_i(n)=p(\xi_n=i)$ называется **распределением**.

Рассмотрим **матрицу переходных вероятностей** $\big(p_{i,j}(k,n)\big), i,j \in X$. В ней значения $k$ и $n$ — фиксированные моменты времени. $i$ — номер строки, $j$ — номер столбца. Еще может обозначаться как $P(k,n)$.

Рассмотрим вектор-строку $\pi(n)=\big(\pi_i(n)\big), i \in X$. Такой вектор называется **распределением цепи в момент $n$**. Тогда $\pi(0)$ **начальное распределение цепи**.

*Справедливо утверждение.* 
Пусть есть какие-то моменты времени $n_1, \ldots, n_m$, и есть состояния $i_1, \ldots, i_m\in X$, тогда совместная вероятность $P(\xi_{n_1}=i_1, \ldots,\xi_{n_m}= i_m)$ единственным образом выражается через переходные вероятности и начальное распределение.

Рассмотрим $P(\xi_{n_1}=i_1, \ldots,\xi_{n_m}= i_m)$. Допишем в конец начальным момент времени
$$P(\xi_{n_1}=i_1, \ldots,\xi_{n_m}= i_m)=$$
$$=\sum_{i_0 \in X}P(\xi_{n_1}=i_1, \ldots,\xi_{n_m}= i_m, \xi_0=i_0)=$$
$$=\sum_{i_0 \in X}P(\xi_{n_1}=i_1|\xi_{n_2=i_2})P(\xi_{n_2}=i_2,\ldots,\xi_0=i_0)=$$
$$=\sum_{i_0 \in X}P(\xi_{n_1}=i_1|\xi_{n_1=i_2})P(\xi_{n_2}=i_2|\xi_{n_3=i_3})\cdot\ldots\cdot P(\xi_0=i_0)$$

# однородные цепи Маркова

$\xi_n$ — **однородная цепь Маркова**, если выполнено следующее свойство: если для любых состояний $i, j \in X$, где $X$ — пространство состойний этой цепи, и для любых моментов времени $n \ge k \ge 0$ вероятность перехода из состояния $i$  в состояние $j$ из момента времени $k$ в момент времени $n$ зависит только от разности между $n$ и $k$
$$P_{i,j}(k,n) = P_{i,j}(0, n-k)$$
Будем обозначать $P_{i,j}(s):= P_{i,j}(0,s)$.

Матрица переходных вероятностей будет зависеть от одного аргумента $s$. 
$$P(s)=P_{i,j}(s),i,j \in X$$
Положим $P(1):=P$. 

***Лемма***:
Какие бы ни были взяты моменты времени $n$ и $m$:
$$P(n+m)=P(n)\cdot P(m)$$
и, кроме того, распределение $\pi$ в момент времени $n+m$:
$$\pi(n+m)=\pi(n)\cdot P(m)$$
*Следствие:*
$P(n)$ — это всегда $P^n$
$$P(n)=P^n$$
Кроме того, через матрицу и начальное распределение можно выразить $\pi(n)$
$$\pi(n)=\pi(0)P^n$$

# стационарное и предельное распределения

Пусть $\xi_n$ — однородная марковская цепь с фазовым пространством $X$ и матрицей переходных вероятностей $P$. $\pi$ — это стационарное распределение, если выполнено
$$\pi = \pi P$$
Если положить, что начальное распределение равно стационарному, 
$$\pi(0)\Rightarrow \pi(1)=\pi P=\pi \Rightarrow\pi(2)=\pi P=\pi,\ldots$$
в каждый момент времени распределение остается одним и тем же.

$\pi$ называется **предельным распределением**, если какое бы ни было взято начальное распределение $\pi(0)$
$$\lim_{n\to \infty}\pi(0)P^n=\pi$$
## Эргодическая теорема

Пусть $\xi_n$ — однородная марковская цепь с конечным пространством состояний $X$. Пусть существует такое $n$, что $\exists P_{i,j}(n)>0,\forall i,j\in  X$, тогда существует распределение, которое является одновременно стационарным и предельным, и при этом оно является единственным
$$\forall i,j \in X\exists\lim_{n\to \infty}P_{i,j}(n)=\pi_{j}$$
# переход от одной марковской цепи к другой

Рассмотрим марковскую однородную цепь $\xi_n$. Пусть ее пространство состояний имеет вид
$$X=\{1,2,3\}$$
Пусть в начальный момент времени $\xi_0$ почти наверное равно единице
$$\xi_0=1$$
и дана матрица переходных вероятностей $P$
$$\begin{pmatrix}
3/7 & 3/7 & 1/7\\
1/11 & 2/11 & 8/11 \\
1/11 & 4/11 & 6/11
\end{pmatrix}$$
обозначим
$$\eta_n=I(\xi_n=1)+2I(\xi_n\ne1)$$
Требуется доказать, что $\eta_n$ является однородной марковской цепью и найти ее матрицу переходных вероятностей.

$$P(\eta_n=x_n|\eta_{n-1}=x_{n-1}, \ldots)=\frac{P(\eta_n=x_n,\eta_{n-1}=x_{n-1}, \ldots)}{P(\eta_{n-1}=x_{n-1}, \ldots)}=$$
посмотрим на числитель, взяв $n=3$
$$P(\eta_3=1,\eta_2=2, \eta_1=2, \eta_0=1)=P(\xi_3=1,\xi_2\in\{2,3\},\xi_1\in\{2,3\},\xi_0=1)=$$
$$=P(\xi_3=1,\xi_2=2,\xi_1=2,\xi_0=1)+P(\xi_3=1,\xi_2=3,\xi_1=2,\xi_0=1)+$$
$$+P(\xi_3=1,\xi_2=2,\xi_1=3,\xi_0=1)+P(\xi_3=1,\xi_2=3,\xi_1=3,\xi_0=1)=$$
$$=P(\xi_3=1|\xi_2=2)P(\xi_2=2,\xi_1=2\xi_0=1)+\ldots=$$
$$=P(\xi_3=1|\xi_2=2)P(\xi_2=2,\xi_1\in\{2,3\},\xi_0=1)+P(\xi_3=1|\xi_2=3)P(\xi_2=3,\xi_1\in\{2,3\},\xi_0=1)=$$
по матрице вероятность перехода из 2 в 1 и из 3 в 1 совпадают и равны $1/11$
$$=\frac{1}{11}\bigg(P(\xi_2=2,\xi_1\in\{2,3\},\xi_0=1)+P(\xi_2=3,\xi_1\in\{2,3\},\xi_0=1)\bigg)=$$
$$=\frac{1}{11}\bigg(P(\xi_2=\{2,3\},\xi_1\in\{2,3\},\xi_0=1)\bigg)=$$
$$=\frac{1}{11}P(\eta_2=2,\eta_1=2,\eta_0=1)$$
это как раз то, что стояло в знаменателе условной вероятности. Если поделить, то останется $1/11$.

$$P(\eta_n=x_n|\eta_{n-1}=x_{n-1})$$

Найдем матрицу переходных вероятностей
$$P(\eta_2=1|\eta_1=1)=P(\xi_2=1|\xi_1=1)=\frac{3}{7}$$
тогда
$$\tilde{P}=
\begin{pmatrix}
3/7 & 4/7 \\
1/11 & 10/11
\end{pmatrix}$$


# марковская цепь со стационарным распределением и без предельного

Рассмотрим матрицу переходных вероятностей
$$\begin{pmatrix}
0 & 1 \\
1 & 0
\end{pmatrix}$$
при возведении в квадрат:
$$\begin{pmatrix}
0 & 1 \\
1 & 0
\end{pmatrix}^2=
\begin{pmatrix}
1 & 0 \\
0 & 1
\end{pmatrix}$$
при возведении в куб
$$\begin{pmatrix}
0 & 1 \\
1 & 0
\end{pmatrix}^3=
\begin{pmatrix}
0 & 1 \\
1 & 0
\end{pmatrix}$$
Значит, что предельного распределения не существует, потому что, какое бы ни было начальное распределение, при умножении на матрицу в четной степени
$$(1,0)P^{2k}=(1,0)$$
при умножении на матрицу в нечетной степени
$$(1,0)P^{2k+1}=(0,1)$$

Стационарное распределение существует
$$(p_1, p_2)\begin{pmatrix}
0 & 1 \\
1 & 0
\end{pmatrix}=(p_1,p_2)$$
это выполняется тогда и только тогда, когда $p_1=p_2$, а это значит, что стационарное распределение имеет вид
$$\bigg(\frac{1}{2},\frac{1}{2}\bigg)$$

	

# марковская цепь без стационарного и предельного распределений

Рассмотрим матрицу переходных вероятностей
$$\begin{pmatrix}
0 & 1 & 0 & 0 & 0 & \cdots  \\
0 & 0 & 1 & 0 & 0 & \cdots  \\
0 & 0 & 0 & 1 & 0 & \cdots  \\
0 & 0 & 0 & 0 & 1 & \cdots  \\
&&\cdots
\end{pmatrix}$$
уравнение
$$\pi P=\pi$$
превратится
$$\begin{cases}
0= \pi_1 \\
\pi_1=\pi_2 \\
\pi_2=\pi_3 \\
\cdots
\end{cases}=(0,0,0,0,\ldots)$$
Это означает, что стационарного распределения не существуент.

Если умножить вектор $\pi$ на матрицу $P$
$$\pi P=(0, \pi_1, \pi_2, \ldots)$$
Если умножить на матрицу в квадрате
$$\pi P^2=(0, 0, \pi_1, \ldots)$$
чем в большую степень возводим, тем больше в начале нулей. Это значит, что в пределе получается вектор из всех нулей, а это означает, что предельного распределения не существует.