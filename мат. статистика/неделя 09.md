 
Пусть наблюдение $X$ имеет распределение $P$, причем $P\in\mathcal{P}$. Статистическая гипотеза — это предположение общего вида о распределении $P$:
$$H_0:P\in\mathcal{P_0},\mathcal{P_0}\in\mathcal{D}$$

Если гипотеза $H_0$ неверна, то переходим к рассмотрению альтернативной гипотезы $H_1$
$$H_1:P\in \mathcal{P_1}$$
При этом их дизъюнктное объединение принадлежит $\mathcal{P}$.
$$\mathcal{P_0}\sqcup\mathcal{P_1}\subset\mathcal{P}$$

Пусть $S$ — подмножество выборочного пространства $S\subset X$. Если правило проверки гипотезы $H_0$ таково, что 
- если $X\in S$, то отвергаем $H_0$
- если $X\notin S$, то не отвергаем $H_0$
то данное правило называется критерием проверки гипотезы $H_0$

Само множество $S$ называется критическим множеством или критерием.

# ошибки I и II рода

Ошибка I рода — это если отвергнута верная гипотеза.

Ошибка II рода — это если принята неверная гипотеза.

Пусть наблюдение $X\sim P$, $P\in\{P_\theta, \theta\in\Theta\}$, тогда **гипотеза** $H_0$ состоит в том, что $\theta\in\Theta_0$, $H_1:\theta\in\Theta_1$ и $\Theta_0\sqcup\Theta_1\in\Theta$.

**Функция мощности критерия** $S$ определяется по правилу
$$\beta(S,\theta)=P_\theta(X\in S)$$
Функция мощности критерия — это вероятность того, что критерий правильно отвергнет  нулевую гипотезу, когда она действительно ложна. Другими словами, это способность критерия обнаружить эффект, если он действительно существует.


Число $\alpha$ такое, что для любого $\theta\in\Theta_0$ $\beta(\theta,S)\le \alpha$ называется **уровнем значимости критерия**.

Уровень значимости — это вероятность отвергнуть нулевую гипотезу, когда она на самом деле верна. Это один из способов контроля над ошибками первого рода.


Минимальный уровень значимости критерия называется его **размером**.


Критерий $S$ называется несмещенным критерием, если выполнено соотношение 
$$\sup_{\theta\in\Theta_0} \beta(S,\theta)\le \inf_{\theta\in\Theta_1} \beta(S,\theta)$$
Несмещённый статистический критерий — это такой критерий, при использовании которого вероятность ошибки первого рода (отвергнуть верную нулевую гипотезу) и вероятность ошибки второго рода (принять неверную нулевую гипотезу) одинаковы. В идеальном случае, мы хотим, чтобы обе эти вероятности были как можно меньше, но в реальности часто приходится искать некий баланс между ними.

Критерий $S$ называется состоятельным критерием, если для любого $\theta$ из $\Theta_1$
$$\beta(S,\theta)\xrightarrow[n\to\infty]{}1$$
Состоятельный критерий дает оценку параметра, которая приближается к истинному значению параметра по мере увеличения размера выборки. То есть, чем больше данных мы собираем, тем ближе наши оценки к истинному значению параметра.


$$P_\theta(X\notin S)=1-P_\theta(X\in S)=1-\beta(S,\theta), \theta\in\Theta_1$$
Если $X\notin S$, то делаем вывод в пользу основной гипотезы, иначе — в пользу альтернативной.

Критерий $S$ уровня значимости $\alpha$ мощнее критерия $R$ уровня значимости $\alpha$, если для любого $\theta\in\Theta_1$
$$\beta(S,\theta)\ge\beta(R,\theta)$$
Если критерий $S$ мощнее любого другого критерия $R$, то критерий $S$ называется **равномерно наиболее мощным критерием** данной задачи.

Равномерно наиболее мощный критерий в статистике — это такой критерий, который имеет **наибольшую мощность** (то есть вероятность правильно отвергнуть нулевую гипотезу, когда она ложна) среди всех возможных критериев того же уровня значимости для всех возможных значений параметра в рамках альтернативной гипотезы.

Мощность критерия — это его способность обнаружить эффект, если он действительно существует. Если у вас есть несколько разных критериев, которые вы могли бы использовать, и вы выбираете тот, который имеет наибольшую мощность, вы увеличиваете свои шансы обнаружить эффект, если он есть.

## лемма Неймана-Пирсона

Пусть $\mathcal{P}=\{P_\theta,\theta\in\Theta\}$ — доминируемое семейство распределений (у него существует плотность $p(X,\theta)$). Рассмотрим $H_0: \theta=\theta_0$ и $H_1: \theta=\theta_1$. 

Отношение правдоподобий:
$$L(X)=\frac{p(X,\theta_1)}{p(X,\theta_0)}$$
В общем случае $X$ — это наблюдение.

Если существует $c_\alpha>0$ такое, что 
$$P_{\theta_0}(L(X)>c_\alpha)=\alpha$$
в таком случае критерий $\{L(X)>c_\alpha\}$ является **равномерно наиболее мощным критерием** для задачи различения двух простых гипотез уровня значимости $\alpha$.

Еще записывают как
$$\{p(X,\theta_1)>c_\alpha p(X,\theta_0)\}$$

### пример

Пусть есть выборка из распределения бернулли $X_1,\ldots,X_n$ $Bern(\theta)$. Построить равномерно наиболее мощный критерий для различения двух гипотез
$$H_0:\theta=\theta_0 \text{ vs }H_1:\theta=\theta_1$$
в двух случаях:
- $\theta_0>\theta_1$
- $\theta_1>\theta_0$

Записать критерий Неймана-Пирсона.

Правдоподобие для Бернулли
$$p(X,\theta_0)=\theta_0^{\sum X_i}(1-\theta_0)^{n-\sum X_i}$$

$$L(X)=\frac{p(X,\theta_1)}{p(X,\theta_0)}=\frac{\theta_1^{\sum X_i}(1-\theta_1)^{n-\sum X_i}}{\theta_0^{\sum X_i}(1-\theta_0)^{n-\sum X_i}}$$

рассмотрим $L(X)\ge c$
$$\{L(X)\ge c\}\Leftrightarrow\frac{\theta_1^{\sum X_i}(1-\theta_0)^{\sum X_i}}{(1-\theta_1)^{\sum X_i}\theta_0^{\sum X_i}}\ge c_1$$
$$\bigg(\frac{\theta_1(1-\theta_0)}{\theta_0(1-\theta_1)}\bigg)^{\sum X_i}\ge c_1$$
случай $\theta_1>\theta_0$
В скобках значение будет больше единицы. Можно взять логарифм и тогда получится
$$\sum X_i\ge c_2$$
нужно выбрать $c_2$ равным квантилю уровня $1-\alpha$ из биномиального закона с параметрами $n$ и $1-\alpha$.

случай $\theta_1<\theta_0$
$$\sum X_i<c_\alpha$$

## теорема о монотонном отношении правдоподобия

Семейство $\{P_\theta,\theta\in\Theta\}$ является семейством с монотонным отношением правдоподобия, если отношение правдоподобия 
$$\frac{f(X,\theta'')}{f(X,\theta')}$$
является либо неубывающей, либо невозрастающей функцией от некой статистики $T(X)$ при $\theta''>\theta'$.

**теорема**

Пусть $H_0:\theta\le\theta_0 (\theta=\theta_0) \text{ vs } H_1:\theta>\theta_0$ и семейство распределений $P_\theta$ обладает монотонным отношением правдоподобия и отношение правдоподобия возрастает по $T(X)$.  Пусть существует константа $c_\alpha$, что
$$P_{\theta_0}(T(X)>c_\alpha)=\alpha$$
В таком случае критерий $T(X)>c_\alpha$ является равномерно наиболее мощным критерием уровня значимости $\alpha$ для проверки $H_0$ против $H_1$.

## проверка гипотезы о параметре нормального распределения

Пусть есть выборка из нормального закона с параметром $\theta$ и известной дисперсией. Проверяем $H_0: \theta=\theta_0 \text{ vs } H_1:\theta \ne \theta_0$. Используем статистику $\sum X_i$

Доверительный интервал для $\theta$

$$\sum X_i\sim \mathcal{N}(n\theta,n)$$
$$\sqrt{n}(\overline X-\theta)\sim\mathcal{N}(0,1)$$
можно заключить величину между двумя квантилями, тогда доверительный интервал
$$\bigg(\overline X-u_{\frac{1-\alpha/2}{\sqrt{n}}},\overline X+u_{\frac{1-\alpha/2}{\sqrt{n}}}\bigg)$$
уровня доверия $1-\alpha$. 

Если гипотеза $H_0$ верна, то $\theta_0$ попадает в этот интервал с вероятностью $1-\alpha$.

Если гипотеза $H_0$ верна
$$P_{\theta_0}(|\sqrt{n}(\overline X-\theta_0)| > u_{1-\alpha/2})=\alpha$$
Если гипотенза неверна, то выборочное среднее будет стремиться к $\theta$. Вся величина будет стремиться к $+\infty$. Тогда вероятность будет стремиться к 1, то есть это состоятельный критерий.
$$\{|\sqrt{n}(\overline X-\theta_0)| > u_{1-\alpha/2}\}$$
