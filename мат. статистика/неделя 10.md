# критерий Вальда

Пусть есть наблюдение из неизвестного распределения $X\sim P\in\{P_\theta,\theta\in\Theta\}$. Предположим, что имеется асимптотически нормальная оценка параметра $\theta$ для этого распределения
$$\sqrt{n}(\theta^\ast_n-\theta)\xrightarrow[]{d_\theta}\mathcal{N}\big(0,\sigma^2(\theta)\big)$$
при этом параметр $\theta$ — одномерный. Требуется проверить гипотезу $H_0:\theta=\theta_0$ против альтернативы $H_1:\theta\ne\theta_0$
$$\sqrt{n}\frac{(\theta_n^\ast-\theta)}{\sigma(\theta)}\xrightarrow[]{d_\theta}\mathcal{N}(0,1)$$
где $\sigma(\theta)$ положительна и непрерывна по $\theta$. Поскольку $\sigma(\theta^\ast)$ — асимптотически нормальная оценка, то она является и состоятельной оценкой, поэтому можно заменить $\sigma(\theta)$ на $\sigma(\theta^\ast)$.

То есть, поскольку $\theta^\ast_n\xrightarrow[]{P_\theta}\theta$, то по теореме о наследовании сходимости $\sigma(\theta^\ast)\xrightarrow[]{P_\theta}\sigma(\theta)$ и тогда
$$\frac{\sigma(\theta)}{\sigma(\theta^\ast)}\xrightarrow[]{P_\theta}1$$
тогда по лемме Слуцкого
$$\sqrt{n}\frac{(\theta_n^\ast-\theta)}{\sigma(\theta)}\cdot\frac{\sigma(\theta)}{\sigma(\theta^\ast)}\xrightarrow[]{d_\theta}\mathcal{N}(0,1)$$

Критерий Вальда
$$\sqrt{n}\bigg|\frac{\theta^\ast_n-\theta_0}{\sigma(\theta^\ast_n)}\bigg| > u_{1-\alpha/2}\sim\mathcal{N}(0,1)$$
Критерий Вальда — асимптотический. Это означает, что при конечных $n$ уровень значимости $\alpha$ достигаться не будет, он будет достигаться только при стремлении $n$ к бесокнечности.

Критерий Вальда — состоятельный.

# одновыборочный критерий Стьюдента

Выборка $X_1,\ldots,X_n\sim\mathcal{N}(\theta,\sigma^2)$. Проверяем гипотезу
$$H_0:\theta=\theta_0 \text{ vs } H_1:\theta\ne\theta_0$$
С учетом того, что выборка из нормального распределения, возможно построить точный критерий, то есть такой, у которого уровень значимости всегда будет равен $\alpha$.

Возьмем
$$\sum_{i=1}^n X_i\sim\mathcal{N}(n \theta_0,n \sigma^2)$$
если взять выборочное среднее, то его распределение будет
$$\overline{X}\sim\mathcal{N}\bigg(\theta_0,\frac{\sigma^2}{n}\bigg)$$
тогда
$$\frac{\overline{X}-\theta_0}{\sigma/\sqrt{n}}=\sqrt{n}\frac{\overline{X}-\theta_0}{\sigma}\sim\mathcal{N}(0,1)$$
К сожалению, значение $\sigma$ не известно. Воспользуемся выборочной дисперсией. Так как верно соотношение
$$\frac{ns^2}{\sigma^2}\sim\chi^2_{n-1}$$
и $s^2$ не зависит от $\overline{X}$.
$$\frac{\overline{X}-\theta_0}{\sigma/\sqrt{n}}\bigg/\sqrt{\frac{ns^2}{\sigma^2}\bigg/(n-1)}\sim St(n-1)$$
Эта величина будет иметь распределение Стьюдента.
Упростим:
$$\sqrt{n-1}\frac{\overline{X}-\theta_0}{s}$$
тогда получается
$$\sqrt{n-1}\bigg|\frac{\overline{X}-\theta_0}{s}\bigg|>t_{1-\alpha/2}$$
где $t_{1-\alpha/2}$ — квантиль распределения Стьюдента с $(n-1)$ степенью свободы.

Этот критерий точный, потому что статистика критерия при верности гипотезы $H_0$ имеет точное распределения Стюдента.

Критерий состоятельный.

# двухвыборочный критерий Стьюдента

Есть две независимые выборки: $X_1, \ldots, X_n$, имеющая распределение $\mathcal{N}(\mu_1, \sigma_1^2)$ и $Y_1,\ldots,Y_m$, имеющая распределение $\mathcal{N}(\mu_2,\sigma_2^2)$, при этом $\sigma_1^2=\sigma_2^2=\sigma^2$. Гипотеза $H_0:\mu_1=\mu_2$ против альтернативы $H_1: \mu_1\ne\mu_2$.

Из предыдущего критерия можно сделать вывод, что среднее выборочное имеет нормальное распределение
$$\overline{X}\sim\mathcal{N}\bigg(\mu_1,\frac{\sigma^2}{n}\bigg)$$
$$\overline{Y}\sim\mathcal{N}\bigg(\mu_2,\frac{\sigma^2}{m}\bigg)$$
отсюда следует, что, если $H_0$ верна, то 
$$\overline{X}-\overline{Y}\sim\mathcal{N}\bigg(0,\sigma^2\bigg(\frac{1}{n}+\frac{1}{m}\bigg)\bigg)$$
перенесем
$$\sqrt{\frac{nm}{n+m}}\frac{\overline{X}-\overline{Y}}{\sigma}\sim\mathcal{N}(0,1)$$
нужно предложить хорошую оценку для $\sigma$.

В предыдущем случае было найдено, что 
$$\frac{ns^2_X}{\sigma^2}\sim\chi^2_{n-1}$$
$$\frac{ms^2_Y}{\sigma^2}\sim\chi^2_{m-1}$$
выборочные дисперсии будут независимы от своих выборочных средних.

Складывая две эти величины
$$\frac{ns^2_X+ms^2_y}{\sigma^2}\sim \chi^2_{n+m-2}$$
получается
$$\sqrt{\frac{nm}{n+m}}\frac{\overline{X}-\overline{Y}}{\sigma}\bigg/\sqrt{\frac{ns^2_X+ms^2_y}{\sigma^2}\bigg/(n+m-2)}\sim St(n+m-2)$$
упрощая
$$S(X,Y)=\sqrt{\frac{(n+m-2)nm}{n+m}}\cdot\frac{\overline{X}-\overline{Y}}{\sqrt{ns^2_X+ms^2_Y}}$$
Если $|S(X,Y)|>t_{1-\alpha/2}$, то отвергаем гипотезу $H_0$.

где $t_{1-\alpha/2}$ — квантиль распределения Стьюдента с $(n+m-2)$ степенями свободы.

# критерий Фишера для гауссовской линейной модели

Гауссовская линейная модель — это $X=Z\theta+\varepsilon$, где $Z$ — это матрица размера $n\times k$, $\varepsilon$ — это ошибка, имеющая распределение $\mathcal{N}(0,\sigma^2I_n)$.

Оптимальной оценкой является — оценка методом наименьших квадратов
$$\widehat{\theta}=(Z^TZ)^{-1}Z^TX$$
где $\widehat{\theta}\sim\mathcal{N}(\theta,\sigma^2 (Z^TZ)^{-1})$

$H_0:T\theta=\tau$

Пример, $\theta=\begin{pmatrix}\theta_1 \\ \theta_2\end{pmatrix}$ . Проверяем гипотезу $H_0: \theta_1=\theta_2$. Матрицу можно выбрать $T=(1,-1)$, тогда $\tau=0$.

$T\widehat{\theta}$ — это оптимальная оценка для $T\theta$.

$$\hat{t}=T\widehat{\theta}\sim\mathcal{N}(T\theta,T(Z^TZ)^{-1}T^T\sigma^2)$$
обозначим $B=T(Z^TZ)^{-1}T^T$. Матрица $B$ симметрична и положительно определена. Существует $\sqrt{B}$ и $(\sqrt{B})^{-1}$.

Рассмотрим следующую случайную величину
$$\xi=(\sqrt{B})^{-1}\frac{\widehat{t}-t}{\sigma}$$
получится многомерное нормальное распределение 
$$\mathcal{N}(0,(\sqrt{B})^{-1})B(\sqrt{B})^{-1})=\mathcal{N}(0,I_m)$$
$$||\xi||^2=\frac{(\widehat{t}-t)^T(\sqrt{B})^{-1}(\sqrt{B})^{-1}(\widehat{t}-t)}{\sigma^2}=\frac{(\widehat{t}-t)^TB^{-1}(\widehat{t}-t)}{\sigma^2}$$



## пример

Пусть $X_1,\ldots,X_n\sim\mathcal{N}(a_1,\sigma^2)$ и $Y_1,\ldots,Y_m\sim\mathcal{N}(a_2,\sigma^2)$, выборки независимы.
Проверить $H_0: a_1=a_2$.

$$W=\begin{pmatrix}
X_1 \\
\vdots \\
X_n\\
Y_1\\
\vdots\\
Y_m
\end{pmatrix}=\begin{pmatrix}
1 & 0 \\
\vdots & \vdots \\
1 & 0\\
0 & 1\\
\vdots & \vdots \\
0 & 1
\end{pmatrix}\begin{pmatrix}a_1\\a_2\end{pmatrix}+\varepsilon$$
$$Z^TZ=\begin{pmatrix}
1&\cdots&1&0&\cdots&0\\
0&\cdots&0&1&\cdots&1
\end{pmatrix}
\begin{pmatrix}
1 & 0 \\
\vdots & \vdots \\
1 & 0\\
0 & 1\\
\vdots & \vdots \\
0 & 1
\end{pmatrix}=
\begin{pmatrix}
n & 0 \\
0 & m
\end{pmatrix}$$
тогда
$$(Z^TZ)^{-1}=\begin{pmatrix}
1/n & 0 \\
0 & 1/m
\end{pmatrix}$$

$T=(1,-1), \tau=0$

тогда
$$B=T(Z^TZ)^{-1}T^T=\frac{1}{n}+\frac{1}{m}=\frac{n+m}{nm}$$
$$B^{-1}=\frac{nm}{n+m}$$$$\widehat{\theta}=\begin{pmatrix}
\widehat{a}\\
\widehat{b}
\end{pmatrix}=(Z^TZ)^{-1}Z^TW=\begin{pmatrix}
\overline{X}\\
\overline{Y}
\end{pmatrix}$$
$$||X-Z\widehat{\theta}||^2=\sum_{i=1}^n(X_i-\overline{X})^2 + \sum_{i=1}^m(Y_i-\overline{Y})^2$$
теперь можно построить критерий
$$\widehat{t}=T\widehat{\theta}=\overline{X}-\overline{Y}$$
$$\frac{\frac{nm}{n+m}(\overline{X}-\overline{Y})^2}{||X-Z\widehat{\theta}||^2}\cdot\frac{n+m-2}{1}>f_{1-\alpha}$$

$f_{1-\alpha}$  — квантиль распределения Фишера с $(1, n+m-2$) степенями свободы