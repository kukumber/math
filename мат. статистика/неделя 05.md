# достаточные статистики

Пусть есть наблюдение $X$ из неизвестного распределения $P$, которое принадлежит некоторому классу распределений $P_\theta$
$$X\in\{P_\theta,\theta\in \Theta\}$$
Тогда статистика $S(X)$ называется достаточной для семейства $\{P_\theta,\theta\in\Theta\}$, если для любого $B$ из борелевской сигма-алгебры 
$$\forall B\in\mathcal{B}(\mathbb{R}^n)$$
выполнено следующее утверждение
$$P_\theta(X\in B|S(X)=s)$$
не зависит от параметра $\theta$.

Так случается, когда информация о наблюдениях в рамках данного семейства распределения заключена внутри статистики $S(X)$.

Допустим $S(X)$ — это все наблюдение $X$, тогда можно подставить в указанную выше вероятность $X$. В этом случае вероятность будет либо 0, либо 1, потому что либо $S$ принадлежит $B$ и тогда вероятность равна 1, либо не принадлежит, и тогда вероятность равна 0.

Для самого себя всегда наблюдение $X$ является достаточной статистикой.

Суть достаточной статистики состоит в том, что вся информация о параметре $\theta$, которая есть в наблюдении $X$, содержится в этой достаточной статистике. Если эту статистику зафиксировать, то условное распределение $X$ не будет зависеть от параметра $\theta$, другими словами, оно не будет содержать информацию о параметре $\theta$.

Достаточные статистики всегда существуют. Например, само наблюдение $X$ является достаточной статистикой, но такая достаточная статистика не уменьшает размер данных. Желательно, чтобы достаточная статистика была наименьшей из возможных и по размерности совпадала с размерностью параметра $\theta$.

## пример

Докажем, что статистика $\sum X_i$ является достаточной для семейства распределений Бернулли с параметром $\theta$
$$\begin{aligned}
P_\theta(X=x|\sum X_i=s)&= \frac{P_\theta(X_1=x_1,\ldots,X_n=x_n,\sum X_i=s)}{P_\theta(\sum X_i=s)}=
\end{aligned}$$

Что будет, если сумма $x_i\ne s$? Такое невозможно, потому что $x_i$ задают то, чему равна сумма $X_i$. В таком случае можно поставить индикатор того, что сумма $\sum x_i=s$,  иначе эта вероятность равна нулю. При этом в числителе можно не указывать $\sum X_i=s$ потому что $\sum X_i=\sum x_i=s$ 
$$\begin{aligned}
&=I\bigg(\sum x_i=s\bigg)\frac{P_\theta(X_1=x_1,\ldots,X_n=x_n)}{P_\theta(\sum X_i=s)}= \\
\\
&=I\bigg(\sum x_i=s\bigg)\frac{\theta^{\sum x_i}(1-\theta)^{n-\sum x_i}}{C_n^s\theta^s(1-\theta)^{n-s}}=
\end{aligned}$$

выше было обозначено, что сумма $\sum x_i=s$, тогда можно сократить числитель и знаменатель
$$=I\bigg(\sum x_i=s\bigg)\frac{1}{C_n^s}$$

что и доказывает, что сумма $x_i$ в данной модели — достаточная статистика.

# критерий факторизации Неймана-Фишера

## теорема

Пусть $X$ — наблюдение из неизвестного распределения $P\in\{P_\theta, \theta\in\Theta\}$. При этом семейство $\{P_\theta, \theta\in\Theta \}$ доминируемое, то есть такое, для которого существует функция правдоподобия. Тогда статистика $S(X)$ является **достаточной** для данного семейства распределений тогда и только тогда, когда функция правдоподобия наблюдения $X$ представима в следующем виде
$$f_\theta(x)=\psi\big(S(X),\theta\big)\cdot h(X)$$
Это означает, что только функция $\psi$ будет зависеть от $\theta$, функция $h$ может зависить от $n$. Функция $\psi$ зависит от наблюдения только через статистику $S(X)$.

## задача

Пусть $X_1,\ldots,X_n$ — выборка из нормального распределения $\mathcal{N}(a, \sigma^2)$. Найти достаточную статистику.

Следует ориентироваться на количество параметров: сколько параметров, столько и элементов в достаточной статистике.

Сначала нужно найти функцию правдоподобия.
$$\begin{aligned}
f_\theta(X)&=\bigg(\frac{1}{\sqrt{2\pi\sigma^2}}\bigg)^n\cdot \exp\bigg(-\frac{\sum_{i=1}^n(X_i-a)^2}{2\sigma^2}\bigg)= \\
&=\bigg(\frac{1}{\sqrt{2\pi\sigma^2}}\bigg)^n\cdot\exp\bigg(-\frac{a\sum_{i=1}^nX_i}{2\sigma^2}+\frac{2\sum_{i=1}^nX_i^2}{2\sigma^2}-\frac{na^2}{2\sigma^2}\bigg)
\end{aligned}$$
В качестве достаточной статистики можно выбрать $(\sum X_i^2, \sum X_i)$.

# теорема Колмогорова-Блекуэлла-Рао

Пусть $\hat\theta(X)$ — это несмещенная оценка параметра $\tau(\theta)$, а $S(X)$ — достаточная статистика. Определим статистику $\tilde{\theta}=E_\theta(\hat{\theta}|S(X))$, которая обладает следующими свойствами:

1. $E_\theta\tilde{\theta}=E_\theta\hat{\theta}=\tau(\theta)$, потому что есть свойство полной вероятности для условных математических ожиданий, то есть она несмещенная
2. $D_\theta(\tilde{\theta})\le D_\theta\hat{\theta}$
3. Равенство дисперсий будет тогда и только тогда, когда исходная оценка является функцией от достаточной статистики.

Оптимальная оценка — это наилучшая оценка в среднеквадратическом подходе в классе несмещенных оценок.

Если функция $\tau(\theta)$ допускает оптимальное оценивание, тогда оптимальная оценка обязательно будет функцией от достаточной статистики.


# полные статистики

Статистика $S(X)$ называется полной для семейства распределений $\{P_\theta,\theta\in\Theta\}$, если для любой функции $f(X)$ такой, что $E_\theta f(S(X))=0$ для любого $\theta$, выполнено, что $f(S(X))=0$ почти наверное.

Это нам дает единственность функции от достаточной статистики, которая несмещенно оценивает $\tau(\theta)$. Потому что, если у нас есть две функции $f_1(S(X))$ и $f_2(S(X))$ — две несмещенные оценки $\tau(\theta)$:
$$E_\theta f_1(S(X))=E_\theta f_2(S(X))=\tau(\theta)$$
тогда можно рассмотреть функцию $f=f_1-f_2$. Ее математическое ожидание — это функция от $S(X)$ и оно равно нулю. В случае, если статистика полная, то функция будет равна нулю почти наверное по мере $P_\theta$. То есть, функция достаточной статистики, которая несмещенно оценивает $\tau(\theta)$ будет всего одна, она и будет оптимальной оценкой.


## задача

Пусть $X_1,\ldots,X_n$ — выборка из распределения Бернулли $Bern(\theta)$. Доказать, что $\sum X_i$  — полная статистика для данной модели.

$\sum X_i$ будет иметь биномиальное распределение $Bin(n, \theta)$

Предположим, что для некоторой функции $f$ выполнено условие
$$E_\theta f \bigg(\sum X_i\bigg)=0$$

Можно записать в явной форме
$$\sum_{k=0}^nf(k)\theta^k(1-\theta)^{n-k}=0$$
$$\sum_{k=0}^nf(k)\bigg(\frac{\theta}{1-\theta}\bigg)^k=0,\forall\theta\in(0,1)$$
это означает, что для любого $k\in(0,n)$ функция $f(k)=0$. 


# оптимальные оценки

Пусть $S(X)$ — полная достаточная статистика для семейства распределений $\{P_\theta,\theta\in\Theta\}$, а $\hat\theta(X)$ — несмещенная оценка параметра $\tau(\theta)$. Тогда оценка
$$\tilde\theta(X)=E(\hat\theta(X)|S(X))$$
является оптимальной оценкой для параметра $\tau(\theta)$.

Оптимальная оценка единственная с точностью до почти наверное.

Если $S(X)$ — полная достаточная статистика, а $\varphi(X)$ — решение уравнения несмещенности
$$E_\theta\varphi(S(X))=\tau(\theta)$$
то оказывается, что $\varphi(S(X))$ — это оптимальная оценка для $\tau(\theta)$.

## задача

Пусть $X_1,\ldots,X_n$ — выборка из равномерного распределения $R[0,\theta]$. Найти оптимальную оценку параметра $\theta$.

$$f_\theta(X)=\frac{1}{\theta^n}I(X_{(n)}\le\theta)$$
тогда $S(X)=X_{(n)}$ — достаточная статистика.

нужно найти функцию
$$E_\theta f(X_{(n)})=0$$

плотность для $X_{(n)}$
$$p_{X_{(n)}}(X)=\frac{nX^{n-1}}{\theta^n}I(X\in[0,\theta])$$
тогда
$$\int_0^\theta f(x)\frac{nx^{n-1}}{\theta^n}dx=0$$
$$\int_0^\theta f(x)x^{n-1}dx=0$$
$$\frac{\partial}{\partial \theta}f(\theta)\theta^{n-1}=0$$
$$f(\theta)=0,\forall \theta$$

теперь нужно угадать такую функцию $\varphi$, что матожидание по мере $P_\theta$ будет равно $\theta$.

Матожидание $n$ порядковой статистики
$$E_\theta X_{(n)}=\frac{n\theta}{n+1}$$
оптимальная оценка
$$\frac{n+1}{n}X_n$$
тогда
$$E_\theta\frac{n+1}{n}X_n=\theta$$

## задача

Пусть $X_1,\ldots,X_n$ — выборка из распределения Бернулли $Bern(\theta)$, где $X_1\sim Bin(1, \theta), \theta\in (0,1)$. 

Оптимальная оценка $\tau(\theta)=D(X_1)=\theta(1-\theta)$

**1 шаг**. Поиск достаточной статистики по критерию факторизации. 

Для этого нужно выписать правдоподобие, т. е. плотность всей выборки, которую мы рассматриваем, как функцию от параметра $\theta$
$$L(X,\theta)=\prod_{i=1}^n\theta^{X_i}(1-\theta)^{1-X_i}=\theta^{n \overline X}(1-\theta)^{1-n \overline X}$$
теперь нужно представить функцию в виде двух множителей:  один зависит только от $X$, а второй зависит только от $\theta$ и от $X$ он зависит только через достаточную статистику. В качестве первого множителя можно взять 1, а само правдоподобие — второй множитель.

Отсюда мы получаем, что $\overline X$ (или $\sum X_i$) — достаточная статистика.

**2 шаг**. Нужно проверить **полноту** $S(X)=\sum X_i$, чтобы убедиться, что функция достаточной статистики, которая несмещенно оценивает функцию $\tau(\theta)$, всего одна.

Так как $S(X)$ — это сумма независимых одинаково распределенных биномиальных величин, поэтому она будет $\sim Bin(n, \theta)$.

Уравнение:
$$E_\theta\varphi(S(X))=0,\forall\theta\in(0,1)$$
Так как распределение $S(X)$ мы выяснили, то математическое ожидание можно записать как сумму по всем возможным значениям статитики $S(X)$. Она принимает значения от 0 до $n$
$$\sum_{k=0}^n \varphi(k)C_n^k\theta^k(1-\theta)^{1-k}=0, \forall\theta\in(0,1)$$
можно объединить в один множитель
$$\sum_{k=0}^n\varphi(k)C_n^k\bigg(\frac{\theta}{1-\theta}\bigg)^k=0,\forall\theta\in(0,1)$$
обозначим $\frac{\theta}{1-\theta}=z$, которая может принимать значения $(0,+\infty)$
$$\sum_{k=0}^n\varphi(k)C_n^kz^k=0, \forall z>0$$
Слева стоит многочлен максимальной степени $n$, потому как некоторые значения $\varphi$ могут быть нулевыми и тогда некоторые коэффициенты могут быть равны нулю.

Многочлен степени ровно $n$ имеет $n$ нулей, а здесь нулей гораздо больше, то это означает, что все коэффициенты $\varphi(k)C_n^k$ должны быть нулевыми. Поскольку $C_n^k$  — ненулевая величина, получается, что все $\varphi(k)=0, \forall k=0,\ldots,n$. Это и означает, что $\varphi(S(X))=0$ почти наверное. 

**3 шаг.** Найти $\varphi(S(X))$ — измеримую функцию от полной достаточной статистики $S(X)$, несмещенно оценивающую
$$E_\theta\varphi(S(X))=\tau(\theta)$$

То, что мы хотим найти
$$\tau(\theta)=D_\theta X_1=\theta-\theta^2$$
для $\theta$ оптимальная оценка есть $\overline X$, 
$$E_\theta\overline X=\theta$$
для $\theta^2$
$$E_\theta(\overline X^2)=D_\theta\overline X+(E_\theta\overline X)^2=\frac{\theta-\theta^2}{n}+\theta^2$$
$$E_\theta(\overline X- \overline X^2)=(\theta-\theta^2)-\frac{\theta-\theta^2}{n}=\bigg(1-\frac{1}{n}\bigg)(\theta-\theta^2)=\frac{n-1}{n}\tau(\theta)$$
Теперь эту оценку нужно умножить на $\frac{n}{n-1}$ и тогда она будет несмещенно оценивать $\tau(\theta)$
$$\frac{n}{n-1} \overline X(1-\overline X)$$
и эта оценка будет оптимальной для $\tau(\theta)=\theta(1-\theta)$.

## задача

Пусть $X_1,\ldots,X_n$ — выборка из распределения Бернулли $Bern(\theta)$, где $X_1\sim Bin(1, \theta), \theta\in (0,1)$.
Какие функции $\tau(\theta)$ допускают оптимальное оценивание?

Решение можно начинать с того, что нужно определить, какие функции можно оценить несмещенно. Рассмотрим любую измеримую функцию от выборки
$$E_\theta\varphi(X)=\sum_{X\in\{0,1\}}\varphi(X)\cdot\theta^{\sum X_i}(1-\theta)^{n-\sum X_i}$$
В произведении получится многочлен не выше степени $n$. Можно оценить оптимально. Для этого достаточно привести оптимальные оценки для одного слагаемого $\tau(\theta)=\theta^m, m\le n$.

Тогда весь многочлен будет линейной комбинацией оценок.

Первый и второй шаги — поиск достаточной статистики и проверка, что она полная (см. предыдущую задачу.)

**3 шаг.** Уравнение несмещенности
$$E_\theta\varphi(S(X))=\theta^m, \forall \theta\in(0,1)$$
слева математическое ожидание
$$\sum_{k=0}^n\varphi(k)C_n^k\theta^k(1-\theta)^{n-k}=\theta^m, \forall\theta\in \Theta$$
$$\sum_{k=0}^n\varphi(k)C_n^k\bigg(\frac{\theta}{1-\theta}\bigg)^k=\frac{\theta^m}{(1-\theta)^n}$$
обозначим $\frac{\theta}{1-\theta}=z$, которая может принимать значения $(0,+\infty)$
$$\sum_{k=0}^n\varphi(k)C_n^kz^k=z^m(z+1)^{n-m}, \forall z>0$$
$$\sum_{k=0}^n\varphi(k)C_n^kz^k=z^m\sum_{i=0}^{n-m}C_{n-m}^iz^i=\sum_{k=m}^nC_{n-m}^{k-m}z^k, \forall z>0$$
тогда
$$\varphi(k)=0, k<m$$
$$\varphi(k)=\frac{C_{n-m}^{k-m}}{C_n^k},n\ge k\ge m$$
можно упростить
$$\frac{C_{n-m}^{k-m}}{C_n^k}=\frac{(n-m)!k!(n-k)!}{(k-m)!(n-k)!n!}=\frac{k!/(k-m)!}{n!/(n-m)!}$$
обозначим 
$$(k)_a = k(k-1)\cdot\ldots\cdot(k-a+1)=\frac{k!}{(k-a)!}$$
тогда можно
$$\varphi(k)=\frac{(k)_m}{(n)_m}$$
Тогда оптимальная оценка для $\tau(\theta)=\theta^m$
$$\frac{(\sum X_i)_m}{(n)_m}$$



# случай экспоненциального семейства распределений

Пусть семейство $\{P_\theta,\theta\in\Theta\}, \dim \Theta=k$ является доминируемым (у него существует функция правдоподобия). Тогда, если правдоподобие выборки 
$$f_\theta(X)=\exp\bigg(\sum_{i=1}^k u_i(X)a_i(\theta)+S(X)+d(\theta)\bigg)$$
то это семейство принадлежит экспоненциальному семейству распределений.

Плотность у такого распределения
$$p_\theta(X)=h(X)\cdot \exp\bigg(\sum_{i=1}^k 
u_i(X)a_i(\theta)+v(\theta)\bigg)$$


## теорема об экспоненциальном семействе

Пусть семейство $\{P_\theta,\theta\in\Theta\}$ принадлежит экспоненциальному семейству распределений. Все функции $a_i(\theta)$ линейно независимые в совокупности, а множество $\Theta$ является телесным, то есть, если она содержит окрестности какой-то точки, то она обязана содержать и саму точку. Тогда $T(X)=(u_1(X),\ldots, u_k(X))$ — это полная достаточная статистика в данной модели. 


## задача 

Пусть $X_1,\ldots,X_n$ — выборка из нормального распределения, $X_1\sim\mathcal{N}(\theta, 1), \theta\in\mathbb{R}$
Оптимально оценить функцию распределения
$$\tau(\theta)=P_\theta(X_1\le x)$$
Хорошей оценкой для функции распределения является эмпирическая функция распределения, но она никак не использует тот факт, что выборка из нормального распределения.

Обозначим функцию распределения нормального распределения как $\Phi(X)$.

Если из неравенства с обоих сторон вычесть $\theta$, тогда 
$$\tau(\theta)=P_\theta(X_1\le x_0)=\Phi(x_0-\theta)$$
Это монотонное, непрерывное, гладкое, взаимнооднозначное преобразование.


